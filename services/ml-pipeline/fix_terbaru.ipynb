{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memeriksa folder1: dataset/training\\Rendah\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Abdul Aziz_clip1.mp4\n",
      "Extraction complete for Abdul Aziz_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Abdul Aziz_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Abdul Aziz_clip2.mp4\n",
      "Extraction complete for Abdul Aziz_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Abdul Aziz_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Abian Agung Shafiqri_clip1.mp4\n",
      "Extraction complete for Abian Agung Shafiqri_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Abian Agung Shafiqri_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Abian Agung Shafiqri_clip2.mp4\n",
      "Extraction complete for Abian Agung Shafiqri_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Abian Agung Shafiqri_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Abima Fadricho S_clip1.mp4\n",
      "Extraction complete for Abima Fadricho S_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Abima Fadricho S_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Abima Fadricho S_clip2.mp4\n",
      "Extraction complete for Abima Fadricho S_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Abima Fadricho S_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Ahmad Mumtaz Haris_clip1.mp4\n",
      "Extraction complete for Ahmad Mumtaz Haris_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Ahmad Mumtaz Haris_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Ahmad Mumtaz Haris_clip2.mp4\n",
      "Extraction complete for Ahmad Mumtaz Haris_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Ahmad Mumtaz Haris_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Aji Hamdani_clip1.mp4\n",
      "Extraction complete for Aji Hamdani_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Aji Hamdani_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Aji Hamdani_clip2.mp4\n",
      "Extraction complete for Aji Hamdani_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Aji Hamdani_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Aleron Tsafif Rakha_clip1.mp4\n",
      "Extraction complete for Aleron Tsafif Rakha_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Aleron Tsafif Rakha_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Aleron Tsafif Rakha_clip2.mp4\n",
      "Extraction complete for Aleron Tsafif Rakha_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Aleron Tsafif Rakha_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Athiyan Aqil Muhammad_clip1.mp4\n",
      "Extraction complete for Athiyan Aqil Muhammad_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Athiyan Aqil Muhammad_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Athiyan Aqil Muhammad_clip2.mp4\n",
      "Extraction complete for Athiyan Aqil Muhammad_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Athiyan Aqil Muhammad_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Cyndu Fathur Rahman_clip1.mp4\n",
      "Extraction complete for Cyndu Fathur Rahman_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Cyndu Fathur Rahman_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Cyndu Fathur Rahman_clip2.mp4\n",
      "Extraction complete for Cyndu Fathur Rahman_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Cyndu Fathur Rahman_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Dany Fatihul Ihsan_clip1.mp4\n",
      "Extraction complete for Dany Fatihul Ihsan_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Dany Fatihul Ihsan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Dany Fatihul Ihsan_clip2.mp4\n",
      "Extraction complete for Dany Fatihul Ihsan_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Dany Fatihul Ihsan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Dennis Parulian Panjaitan_clip1.mp4\n",
      "Extraction complete for Dennis Parulian Panjaitan_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Dennis Parulian Panjaitan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Dennis Parulian Panjaitan_clip2.mp4\n",
      "Extraction complete for Dennis Parulian Panjaitan_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Dennis Parulian Panjaitan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Dido Imam Padmanegara_clip1.mp4\n",
      "Extraction complete for Dido Imam Padmanegara_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Dido Imam Padmanegara_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Dido Imam Padmanegara_clip2.mp4\n",
      "Extraction complete for Dido Imam Padmanegara_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Dido Imam Padmanegara_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Diva Aji Kurniawan_clip1.mp4\n",
      "Extraction complete for Diva Aji Kurniawan_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Diva Aji Kurniawan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Diva Aji Kurniawan_clip2.mp4\n",
      "Extraction complete for Diva Aji Kurniawan_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Diva Aji Kurniawan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Fadly Nugraha Jati_clip1.mp4\n",
      "Extraction complete for Fadly Nugraha Jati_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Fadly Nugraha Jati_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Fadly Nugraha Jati_clip2.mp4\n",
      "Extraction complete for Fadly Nugraha Jati_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Fadly Nugraha Jati_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Fransiscus Farrel E_clip1.mp4\n",
      "Extraction complete for Fransiscus Farrel E_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Fransiscus Farrel E_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Fransiscus Farrel E_clip2.mp4\n",
      "Extraction complete for Fransiscus Farrel E_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Fransiscus Farrel E_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Gaco Razan Kamil_clip1.mp4\n",
      "Extraction complete for Gaco Razan Kamil_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Gaco Razan Kamil_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Gaco Razan Kamil_clip2.mp4\n",
      "Extraction complete for Gaco Razan Kamil_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Gaco Razan Kamil_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Habibatul Mustofa_clip1.mp4\n",
      "Extraction complete for Habibatul Mustofa_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Habibatul Mustofa_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Habibatul Mustofa_clip2.mp4\n",
      "Extraction complete for Habibatul Mustofa_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Habibatul Mustofa_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Hafizh Muhammad R_clip1.mp4\n",
      "Extraction complete for Hafizh Muhammad R_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Hafizh Muhammad R_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Hafizh Muhammad R_clip2.mp4\n",
      "Extraction complete for Hafizh Muhammad R_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Hafizh Muhammad R_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Hilmi Irfan Naafi'udin_clip1.mp4\n",
      "Extraction complete for Hilmi Irfan Naafi'udin_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Hilmi Irfan Naafi'udin_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Hilmi Irfan Naafi'udin_clip2.mp4\n",
      "Extraction complete for Hilmi Irfan Naafi'udin_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Hilmi Irfan Naafi'udin_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Joyo Sugito_clip1.mp4\n",
      "Extraction complete for Joyo Sugito_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Joyo Sugito_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Joyo Sugito_clip2.mp4\n",
      "Extraction complete for Joyo Sugito_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Joyo Sugito_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Cholilur Rokhman_clip1.mp4\n",
      "Extraction complete for M Cholilur Rokhman_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Cholilur Rokhman_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Cholilur Rokhman_clip2.mp4\n",
      "Extraction complete for M Cholilur Rokhman_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Cholilur Rokhman_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Daffa Wijaya_clip1.mp4\n",
      "Extraction complete for M Daffa Wijaya_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Daffa Wijaya_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Daffa Wijaya_clip2.mp4\n",
      "Extraction complete for M Daffa Wijaya_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Daffa Wijaya_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Nurul Mustofa_clip1.mp4\n",
      "Extraction complete for M Nurul Mustofa_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Nurul Mustofa_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Nurul Mustofa_clip2.mp4\n",
      "Extraction complete for M Nurul Mustofa_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Nurul Mustofa_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Ridlo Febrio Putra_clip1.mp4\n",
      "Extraction complete for M Ridlo Febrio Putra_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Ridlo Febrio Putra_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\M Ridlo Febrio Putra_clip2.mp4\n",
      "Extraction complete for M Ridlo Febrio Putra_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\M Ridlo Febrio Putra_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Moch Reynal Silva Baktiar_clip1.mp4\n",
      "Extraction complete for Moch Reynal Silva Baktiar_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Moch Reynal Silva Baktiar_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Moch Reynal Silva Baktiar_clip2.mp4\n",
      "Extraction complete for Moch Reynal Silva Baktiar_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Moch Reynal Silva Baktiar_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Muhammad Fathurrozak Al Qoroni_clip1.mp4\n",
      "Extraction complete for Muhammad Fathurrozak Al Qoroni_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Muhammad Fathurrozak Al Qoroni_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Muhammad Fathurrozak Al Qoroni_clip2.mp4\n",
      "Extraction complete for Muhammad Fathurrozak Al Qoroni_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Muhammad Fathurrozak Al Qoroni_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Muhammad Rizky Fauzi_clip1.mp4\n",
      "Extraction complete for Muhammad Rizky Fauzi_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Muhammad Rizky Fauzi_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Muhammad Rizky Fauzi_clip2.mp4\n",
      "Extraction complete for Muhammad Rizky Fauzi_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Muhammad Rizky Fauzi_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Mulki Hakim_clip1.mp4\n",
      "Extraction complete for Mulki Hakim_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Mulki Hakim_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Mulki Hakim_clip2.mp4\n",
      "Extraction complete for Mulki Hakim_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Mulki Hakim_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Muzzarina Khaira Akbar_clip1.mp4\n",
      "Extraction complete for Muzzarina Khaira Akbar_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Muzzarina Khaira Akbar_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Muzzarina Khaira Akbar_clip2.mp4\n",
      "Extraction complete for Muzzarina Khaira Akbar_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Muzzarina Khaira Akbar_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Raihan Fazzaufa Rasendriya_clip1.mp4\n",
      "Extraction complete for Raihan Fazzaufa Rasendriya_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Raihan Fazzaufa Rasendriya_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Raihan Fazzaufa Rasendriya_clip2.mp4\n",
      "Extraction complete for Raihan Fazzaufa Rasendriya_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Raihan Fazzaufa Rasendriya_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Rio Bagas Hendrawan_clip1.mp4\n",
      "Extraction complete for Rio Bagas Hendrawan_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Rio Bagas Hendrawan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Rio Bagas Hendrawan_clip2.mp4\n",
      "Extraction complete for Rio Bagas Hendrawan_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Rio Bagas Hendrawan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Sukma Bagus Wahasjuika_clip1.mp4\n",
      "Extraction complete for Sukma Bagus Wahasjuika_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Sukma Bagus Wahasjuika_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Sukma Bagus Wahasjuika_clip2.mp4\n",
      "Extraction complete for Sukma Bagus Wahasjuika_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Sukma Bagus Wahasjuika_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Syahrul Bhudi Ferdiansyah_clip1.mp4\n",
      "Extraction complete for Syahrul Bhudi Ferdiansyah_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Syahrul Bhudi Ferdiansyah_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Syahrul Bhudi Ferdiansyah_clip2.mp4\n",
      "Extraction complete for Syahrul Bhudi Ferdiansyah_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Syahrul Bhudi Ferdiansyah_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Tirta Nurrochman B P_clip1.mp4\n",
      "Extraction complete for Tirta Nurrochman B P_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Tirta Nurrochman B P_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Tirta Nurrochman B P_clip2.mp4\n",
      "Extraction complete for Tirta Nurrochman B P_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Tirta Nurrochman B P_clip2\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Zaki Lazuardi Fersya P_clip1.mp4\n",
      "Extraction complete for Zaki Lazuardi Fersya P_clip1.mp4, saved 260 frames to dataset/training_images\\Rendah\\Zaki Lazuardi Fersya P_clip1\n",
      "Menemukan file .MP4: dataset/training\\Rendah\\Zaki Lazuardi Fersya P_clip2.mp4\n",
      "Extraction complete for Zaki Lazuardi Fersya P_clip2.mp4, saved 260 frames to dataset/training_images\\Rendah\\Zaki Lazuardi Fersya P_clip2\n",
      "Memeriksa folder1: dataset/training\\Sangat Rendah\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Afrizal Dwi S_clip1.mp4\n",
      "Extraction complete for Afrizal Dwi S_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Afrizal Dwi S_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Afrizal Dwi S_clip2.mp4\n",
      "Extraction complete for Afrizal Dwi S_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Afrizal Dwi S_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Andreagazy Iza A_clip1.mp4\n",
      "Extraction complete for Andreagazy Iza A_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Andreagazy Iza A_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Andreagazy Iza A_clip2.mp4\n",
      "Extraction complete for Andreagazy Iza A_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Andreagazy Iza A_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Fajar Bayu Kusuma_clip1.mp4\n",
      "Extraction complete for Fajar Bayu Kusuma_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Fajar Bayu Kusuma_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Fajar Bayu Kusuma_clip2.mp4\n",
      "Extraction complete for Fajar Bayu Kusuma_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Fajar Bayu Kusuma_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Irshandy Aditya Wicaksana_clip1.mp4\n",
      "Extraction complete for Irshandy Aditya Wicaksana_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Irshandy Aditya Wicaksana_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Irshandy Aditya Wicaksana_clip2.mp4\n",
      "Extraction complete for Irshandy Aditya Wicaksana_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Irshandy Aditya Wicaksana_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\M Paksi Satrio_clip1.mp4\n",
      "Extraction complete for M Paksi Satrio_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\M Paksi Satrio_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\M Paksi Satrio_clip2.mp4\n",
      "Extraction complete for M Paksi Satrio_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\M Paksi Satrio_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Nanda Putra Khamdani_clip1.mp4\n",
      "Extraction complete for Nanda Putra Khamdani_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Nanda Putra Khamdani_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Nanda Putra Khamdani_clip2.mp4\n",
      "Extraction complete for Nanda Putra Khamdani_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Nanda Putra Khamdani_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Rama Pramudhita Bhaskara_clip1.mp4\n",
      "Extraction complete for Rama Pramudhita Bhaskara_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Rama Pramudhita Bhaskara_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Rama Pramudhita Bhaskara_clip2.mp4\n",
      "Extraction complete for Rama Pramudhita Bhaskara_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Rama Pramudhita Bhaskara_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Rendy Putra Kusuma_clip1.mp4\n",
      "Extraction complete for Rendy Putra Kusuma_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Rendy Putra Kusuma_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Rendy Putra Kusuma_clip2.mp4\n",
      "Extraction complete for Rendy Putra Kusuma_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Rendy Putra Kusuma_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Septa Purna Surya_clip1.mp4\n",
      "Extraction complete for Septa Purna Surya_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Septa Purna Surya_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Rendah\\Septa Purna Surya_clip2.mp4\n",
      "Extraction complete for Septa Purna Surya_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Rendah\\Septa Purna Surya_clip2\n",
      "Memeriksa folder1: dataset/training\\Sangat Tinggi\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Achmad Mufid_clip1.mp4\n",
      "Extraction complete for Achmad Mufid_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Achmad Mufid_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Achmad Mufid_clip2.mp4\n",
      "Extraction complete for Achmad Mufid_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Achmad Mufid_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Daffa Yudisa A_clip1.mp4\n",
      "Extraction complete for Daffa Yudisa A_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Daffa Yudisa A_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Daffa Yudisa A_clip2.mp4\n",
      "Extraction complete for Daffa Yudisa A_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Daffa Yudisa A_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Dika Dwi Alamsyah_clip1.mp4\n",
      "Extraction complete for Dika Dwi Alamsyah_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Dika Dwi Alamsyah_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Dika Dwi Alamsyah_clip2.mp4\n",
      "Extraction complete for Dika Dwi Alamsyah_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Dika Dwi Alamsyah_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Febiola Lidya S_clip1.mp4\n",
      "Extraction complete for Febiola Lidya S_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Febiola Lidya S_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Febiola Lidya S_clip2.mp4\n",
      "Extraction complete for Febiola Lidya S_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Febiola Lidya S_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Maulana Arya Putra Nugraha_clip1.mp4\n",
      "Extraction complete for Maulana Arya Putra Nugraha_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Maulana Arya Putra Nugraha_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Maulana Arya Putra Nugraha_clip2.mp4\n",
      "Extraction complete for Maulana Arya Putra Nugraha_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Maulana Arya Putra Nugraha_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Muhammad Rayhan_clip1.mp4\n",
      "Extraction complete for Muhammad Rayhan_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Muhammad Rayhan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Muhammad Rayhan_clip2.mp4\n",
      "Extraction complete for Muhammad Rayhan_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Muhammad Rayhan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Putra Zakaria Muzaki_clip1.mp4\n",
      "Extraction complete for Putra Zakaria Muzaki_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Putra Zakaria Muzaki_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Putra Zakaria Muzaki_clip2.mp4\n",
      "Extraction complete for Putra Zakaria Muzaki_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Putra Zakaria Muzaki_clip2\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Rayyan Al Firdausi_clip1.mp4\n",
      "Extraction complete for Rayyan Al Firdausi_clip1.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Rayyan Al Firdausi_clip1\n",
      "Menemukan file .MP4: dataset/training\\Sangat Tinggi\\Rayyan Al Firdausi_clip2.mp4\n",
      "Extraction complete for Rayyan Al Firdausi_clip2.mp4, saved 260 frames to dataset/training_images\\Sangat Tinggi\\Rayyan Al Firdausi_clip2\n",
      "Memeriksa folder1: dataset/training\\Tinggi\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Abid Gimnastyar Alfiansyah_clip1.mp4\n",
      "Extraction complete for Abid Gimnastyar Alfiansyah_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Abid Gimnastyar Alfiansyah_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Abid Gimnastyar Alfiansyah_clip2.mp4\n",
      "Extraction complete for Abid Gimnastyar Alfiansyah_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Abid Gimnastyar Alfiansyah_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Ahmad Fathir Syafaat_clip1.mp4\n",
      "Extraction complete for Ahmad Fathir Syafaat_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Ahmad Fathir Syafaat_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Ahmad Fathir Syafaat_clip2.mp4\n",
      "Extraction complete for Ahmad Fathir Syafaat_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Ahmad Fathir Syafaat_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Akhmad Khoirul Falah_clip1.mp4\n",
      "Extraction complete for Akhmad Khoirul Falah_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Akhmad Khoirul Falah_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Akhmad Khoirul Falah_clip2.mp4\n",
      "Extraction complete for Akhmad Khoirul Falah_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Akhmad Khoirul Falah_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Aulia Adha A I_clip1.mp4\n",
      "Extraction complete for Aulia Adha A I_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Aulia Adha A I_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Aulia Adha A I_clip2.mp4\n",
      "Extraction complete for Aulia Adha A I_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Aulia Adha A I_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Brilyan Satria Wahyuda_clip1.mp4\n",
      "Extraction complete for Brilyan Satria Wahyuda_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Brilyan Satria Wahyuda_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Brilyan Satria Wahyuda_clip2.mp4\n",
      "Extraction complete for Brilyan Satria Wahyuda_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Brilyan Satria Wahyuda_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Broto Agung W_clip1.mp4\n",
      "Extraction complete for Broto Agung W_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Broto Agung W_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Broto Agung W_clip2.mp4\n",
      "Extraction complete for Broto Agung W_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Broto Agung W_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Denny Malik Ibrahim_clip1.mp4\n",
      "Extraction complete for Denny Malik Ibrahim_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Denny Malik Ibrahim_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Denny Malik Ibrahim_clip2.mp4\n",
      "Extraction complete for Denny Malik Ibrahim_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Denny Malik Ibrahim_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Doni Wahyu Kurniawan_clip1.mp4\n",
      "Extraction complete for Doni Wahyu Kurniawan_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Doni Wahyu Kurniawan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Doni Wahyu Kurniawan_clip2.mp4\n",
      "Extraction complete for Doni Wahyu Kurniawan_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Doni Wahyu Kurniawan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Fakridana Ahmad Rayyansyah_clip1.mp4\n",
      "Extraction complete for Fakridana Ahmad Rayyansyah_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Fakridana Ahmad Rayyansyah_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Fakridana Ahmad Rayyansyah_clip2.mp4\n",
      "Extraction complete for Fakridana Ahmad Rayyansyah_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Fakridana Ahmad Rayyansyah_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Farid Fitriansah Alfarizi_clip1.mp4\n",
      "Extraction complete for Farid Fitriansah Alfarizi_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Farid Fitriansah Alfarizi_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Farid Fitriansah Alfarizi_clip2.mp4\n",
      "Extraction complete for Farid Fitriansah Alfarizi_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Farid Fitriansah Alfarizi_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Fatriya Ibnu Ash Shidiqqi_clip1.mp4\n",
      "Extraction complete for Fatriya Ibnu Ash Shidiqqi_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Fatriya Ibnu Ash Shidiqqi_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Fatriya Ibnu Ash Shidiqqi_clip2.mp4\n",
      "Extraction complete for Fatriya Ibnu Ash Shidiqqi_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Fatriya Ibnu Ash Shidiqqi_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Halur Muhammad Abiyyu_clip1.mp4\n",
      "Extraction complete for Halur Muhammad Abiyyu_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Halur Muhammad Abiyyu_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Halur Muhammad Abiyyu_clip2.mp4\n",
      "Extraction complete for Halur Muhammad Abiyyu_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Halur Muhammad Abiyyu_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Juan Felix Antonio_clip1.mp4\n",
      "Extraction complete for Juan Felix Antonio_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Juan Felix Antonio_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Juan Felix Antonio_clip2.mp4\n",
      "Extraction complete for Juan Felix Antonio_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Juan Felix Antonio_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Kinata Dewa Ariandi_clip1.mp4\n",
      "Extraction complete for Kinata Dewa Ariandi_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Kinata Dewa Ariandi_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Kinata Dewa Ariandi_clip2.mp4\n",
      "Extraction complete for Kinata Dewa Ariandi_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Kinata Dewa Ariandi_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Bagus Indrawan_clip1.mp4\n",
      "Extraction complete for M Bagus Indrawan_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Bagus Indrawan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Bagus Indrawan_clip2.mp4\n",
      "Extraction complete for M Bagus Indrawan_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Bagus Indrawan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Iqbal Makmur A_clip1.mp4\n",
      "Extraction complete for M Iqbal Makmur A_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Iqbal Makmur A_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Iqbal Makmur A_clip2.mp4\n",
      "Extraction complete for M Iqbal Makmur A_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Iqbal Makmur A_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Isyad Dany_clip1.mp4\n",
      "Extraction complete for M Isyad Dany_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Isyad Dany_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Isyad Dany_clip2.mp4\n",
      "Extraction complete for M Isyad Dany_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Isyad Dany_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Naufal Syahendra_clip1.mp4\n",
      "Extraction complete for M Naufal Syahendra_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Naufal Syahendra_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Naufal Syahendra_clip2.mp4\n",
      "Extraction complete for M Naufal Syahendra_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Naufal Syahendra_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Tryo Bagus Anugrah P_clip1.mp4\n",
      "Extraction complete for M Tryo Bagus Anugrah P_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Tryo Bagus Anugrah P_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\M Tryo Bagus Anugrah P_clip2.mp4\n",
      "Extraction complete for M Tryo Bagus Anugrah P_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\M Tryo Bagus Anugrah P_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Maulidin Zakaria_clip1.mp4\n",
      "Extraction complete for Maulidin Zakaria_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Maulidin Zakaria_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Maulidin Zakaria_clip2.mp4\n",
      "Extraction complete for Maulidin Zakaria_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Maulidin Zakaria_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Pascalis Dewangga Sandi_clip1.mp4\n",
      "Extraction complete for Pascalis Dewangga Sandi_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Pascalis Dewangga Sandi_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Pascalis Dewangga Sandi_clip2.mp4\n",
      "Extraction complete for Pascalis Dewangga Sandi_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Pascalis Dewangga Sandi_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Ridho Fauzian Pratama_clip1.mp4\n",
      "Extraction complete for Ridho Fauzian Pratama_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Ridho Fauzian Pratama_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Ridho Fauzian Pratama_clip2.mp4\n",
      "Extraction complete for Ridho Fauzian Pratama_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Ridho Fauzian Pratama_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Rifki Setiawan_clip1.mp4\n",
      "Extraction complete for Rifki Setiawan_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Rifki Setiawan_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Rifki Setiawan_clip2.mp4\n",
      "Extraction complete for Rifki Setiawan_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Rifki Setiawan_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Satria Abrar Sambarana_clip1.mp4\n",
      "Extraction complete for Satria Abrar Sambarana_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Satria Abrar Sambarana_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Satria Abrar Sambarana_clip2.mp4\n",
      "Extraction complete for Satria Abrar Sambarana_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Satria Abrar Sambarana_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Stefanus Ageng Budi Utomo_clip1.mp4\n",
      "Extraction complete for Stefanus Ageng Budi Utomo_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Stefanus Ageng Budi Utomo_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Stefanus Ageng Budi Utomo_clip2.mp4\n",
      "Extraction complete for Stefanus Ageng Budi Utomo_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Stefanus Ageng Budi Utomo_clip2\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Yuma Rakha Samodra S_clip1.mp4\n",
      "Extraction complete for Yuma Rakha Samodra S_clip1.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Yuma Rakha Samodra S_clip1\n",
      "Menemukan file .MP4: dataset/training\\Tinggi\\Yuma Rakha Samodra S_clip2.mp4\n",
      "Extraction complete for Yuma Rakha Samodra S_clip2.mp4, saved 260 frames to dataset/training_images\\Tinggi\\Yuma Rakha Samodra S_clip2\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import shutil\n",
    "\n",
    "# # Path untuk video dan output\n",
    "# video_path = 'dataset/video/05_EP03_06.avi'\n",
    "# output_folder = 'dataset/casme_baru/Suprise/05_EP03_06'\n",
    "\n",
    "# # Buat folder output jika belum ada\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Buka video menggunakan OpenCV\n",
    "# vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Ambil frame rate dari video\n",
    "# framePerSecond = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # Variabel untuk menghitung nomor frame\n",
    "# count = 1\n",
    "\n",
    "# while vidcap.isOpened():\n",
    "#     success, image = vidcap.read()  # Baca frame\n",
    "#     if not success:\n",
    "#         break  # Jika tidak ada frame yang dibaca, keluar dari loop\n",
    "\n",
    "#     # Simpan gambar ke folder output dengan nama imgX.jpg\n",
    "#     img_name = f'img{count}.jpg'\n",
    "#     img_path = os.path.join(output_folder, img_name)\n",
    "#     cv2.imwrite(img_path, image)  # Simpan gambar\n",
    "\n",
    "#     # print(f'Saved frame {count} to {img_path}')\n",
    "\n",
    "#     count += 1\n",
    "\n",
    "# # Lepas video setelah selesai\n",
    "# vidcap.release()\n",
    "# print(f\"Extraction complete, saved {count-1} frames to {output_folder}\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "# Path utama\n",
    "base_input_folder = 'dataset/training'\n",
    "base_output_folder = 'dataset/training_images'\n",
    "\n",
    "# Bersihkan folder output jika ada\n",
    "if os.path.exists(base_output_folder):\n",
    "    shutil.rmtree(base_output_folder)\n",
    "\n",
    "# Loop melalui folder dan file dalam folder input\n",
    "for folder1 in os.listdir(base_input_folder):\n",
    "    folder1_path = os.path.join(base_input_folder, folder1)\n",
    "    \n",
    "    print(f\"Memeriksa folder1: {folder1_path}\")\n",
    "    \n",
    "    if os.path.isdir(folder1_path):\n",
    "        for filename in os.listdir(folder1_path):\n",
    "            file_path = os.path.join(folder1_path, filename)\n",
    "            \n",
    "            # Cek apakah file adalah file .avi\n",
    "            if filename.lower().endswith('.mp4') and os.path.isfile(file_path):\n",
    "                print(f\"Menemukan file .MP4: {file_path}\")\n",
    "\n",
    "                # Buat folder output sesuai nama folder\n",
    "                output_folder = os.path.join(base_output_folder, folder1, filename[:-4])  # Hapus ekstensi '.avi' dari nama folder\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "                # Buka video menggunakan OpenCV\n",
    "                vidcap = cv2.VideoCapture(file_path)\n",
    "\n",
    "                # Ambil frame rate dari video\n",
    "                framePerSecond = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "                # Variabel untuk menghitung nomor frame\n",
    "                count = 1\n",
    "\n",
    "                while vidcap.isOpened():\n",
    "                    success, image = vidcap.read()  # Baca frame\n",
    "                    if not success:\n",
    "                        break  # Jika tidak ada frame yang dibaca, keluar dari loop\n",
    "\n",
    "                    # Simpan gambar ke folder output dengan nama imgX.jpg\n",
    "                    img_name = f'img{count}.jpg'\n",
    "                    img_path = os.path.join(output_folder, img_name)\n",
    "                    cv2.imwrite(img_path, image)  # Simpan gambar\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "                # Lepas video setelah selesai\n",
    "                vidcap.release()\n",
    "                print(f\"Extraction complete for {filename}, saved {count-1} frames to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder: d:\\skripsi-ekspresi-mikro\\services\\ml-pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Lihat current working directory\n",
    "print(\"Current folder:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom tersedia: ['Frame', 'Folder Path', 'Label', 'mulut-X1', 'mulut-Y1', 'mulut-Tetha1', 'mulut-Magnitude1', 'mulut-X2', 'mulut-Y2', 'mulut-Tetha2', 'mulut-Magnitude2', 'mulut-X3', 'mulut-Y3', 'mulut-Tetha3', 'mulut-Magnitude3', 'mulut-X4', 'mulut-Y4', 'mulut-Tetha4', 'mulut-Magnitude4', 'mulut-X5', 'mulut-Y5', 'mulut-Tetha5', 'mulut-Magnitude5', 'mulut-X6', 'mulut-Y6', 'mulut-Tetha6', 'mulut-Magnitude6', 'mulut-X7', 'mulut-Y7', 'mulut-Tetha7', 'mulut-Magnitude7', 'mulut-X8', 'mulut-Y8', 'mulut-Tetha8', 'mulut-Magnitude8', 'mulut-X9', 'mulut-Y9', 'mulut-Tetha9', 'mulut-Magnitude9', 'mulut-X10', 'mulut-Y10', 'mulut-Tetha10', 'mulut-Magnitude10', 'mulut-X11', 'mulut-Y11', 'mulut-Tetha11', 'mulut-Magnitude11', 'mulut-X12', 'mulut-Y12', 'mulut-Tetha12', 'mulut-Magnitude12', 'mulut-X13', 'mulut-Y13', 'mulut-Tetha13', 'mulut-Magnitude13', 'mulut-X14', 'mulut-Y14', 'mulut-Tetha14', 'mulut-Magnitude14', 'mulut-X15', 'mulut-Y15', 'mulut-Tetha15', 'mulut-Magnitude15', 'mulut-X16', 'mulut-Y16', 'mulut-Tetha16', 'mulut-Magnitude16', 'mulut-X17', 'mulut-Y17', 'mulut-Tetha17', 'mulut-Magnitude17', 'mulut-X18', 'mulut-Y18', 'mulut-Tetha18', 'mulut-Magnitude18', 'mulut-X19', 'mulut-Y19', 'mulut-Tetha19', 'mulut-Magnitude19', 'mulut-X20', 'mulut-Y20', 'mulut-Tetha20', 'mulut-Magnitude20', 'mulut-X21', 'mulut-Y21', 'mulut-Tetha21', 'mulut-Magnitude21', 'mulut-X22', 'mulut-Y22', 'mulut-Tetha22', 'mulut-Magnitude22', 'mulut-X23', 'mulut-Y23', 'mulut-Tetha23', 'mulut-Magnitude23', 'mulut-X24', 'mulut-Y24', 'mulut-Tetha24', 'mulut-Magnitude24', 'mulut-X25', 'mulut-Y25', 'mulut-Tetha25', 'mulut-Magnitude25', 'mulut-X26', 'mulut-Y26', 'mulut-Tetha26', 'mulut-Magnitude26', 'mulut-X27', 'mulut-Y27', 'mulut-Tetha27', 'mulut-Magnitude27', 'mulut-X28', 'mulut-Y28', 'mulut-Tetha28', 'mulut-Magnitude28', 'mulut-X29', 'mulut-Y29', 'mulut-Tetha29', 'mulut-Magnitude29', 'mulut-X30', 'mulut-Y30', 'mulut-Tetha30', 'mulut-Magnitude30', 'mulut-X31', 'mulut-Y31', 'mulut-Tetha31', 'mulut-Magnitude31', 'mulut-X32', 'mulut-Y32', 'mulut-Tetha32', 'mulut-Magnitude32', 'mulut-X33', 'mulut-Y33', 'mulut-Tetha33', 'mulut-Magnitude33', 'mulut-X34', 'mulut-Y34', 'mulut-Tetha34', 'mulut-Magnitude34', 'mulut-X35', 'mulut-Y35', 'mulut-Tetha35', 'mulut-Magnitude35', 'mulut-X36', 'mulut-Y36', 'mulut-Tetha36', 'mulut-Magnitude36', 'mulut-X37', 'mulut-Y37', 'mulut-Tetha37', 'mulut-Magnitude37', 'mulut-X38', 'mulut-Y38', 'mulut-Tetha38', 'mulut-Magnitude38', 'mulut-X39', 'mulut-Y39', 'mulut-Tetha39', 'mulut-Magnitude39', 'mulut-X40', 'mulut-Y40', 'mulut-Tetha40', 'mulut-Magnitude40', 'mulut-X41', 'mulut-Y41', 'mulut-Tetha41', 'mulut-Magnitude41', 'mulut-X42', 'mulut-Y42', 'mulut-Tetha42', 'mulut-Magnitude42', 'mulut-X43', 'mulut-Y43', 'mulut-Tetha43', 'mulut-Magnitude43', 'mulut-X44', 'mulut-Y44', 'mulut-Tetha44', 'mulut-Magnitude44', 'mulut-X45', 'mulut-Y45', 'mulut-Tetha45', 'mulut-Magnitude45', 'mulut-X46', 'mulut-Y46', 'mulut-Tetha46', 'mulut-Magnitude46', 'mulut-X47', 'mulut-Y47', 'mulut-Tetha47', 'mulut-Magnitude47', 'mulut-X48', 'mulut-Y48', 'mulut-Tetha48', 'mulut-Magnitude48', 'mulut-X49', 'mulut-Y49', 'mulut-Tetha49', 'mulut-Magnitude49', 'mulut-X50', 'mulut-Y50', 'mulut-Tetha50', 'mulut-Magnitude50', 'mulut-X51', 'mulut-Y51', 'mulut-Tetha51', 'mulut-Magnitude51', 'mulut-X52', 'mulut-Y52', 'mulut-Tetha52', 'mulut-Magnitude52', 'mulut-X53', 'mulut-Y53', 'mulut-Tetha53', 'mulut-Magnitude53', 'mulut-X54', 'mulut-Y54', 'mulut-Tetha54', 'mulut-Magnitude54', 'mulut-X55', 'mulut-Y55', 'mulut-Tetha55', 'mulut-Magnitude55', 'mulut-X56', 'mulut-Y56', 'mulut-Tetha56', 'mulut-Magnitude56', 'mulut-X57', 'mulut-Y57', 'mulut-Tetha57', 'mulut-Magnitude57', 'mulut-X58', 'mulut-Y58', 'mulut-Tetha58', 'mulut-Magnitude58', 'mulut-X59', 'mulut-Y59', 'mulut-Tetha59', 'mulut-Magnitude59', 'mulut-X60', 'mulut-Y60', 'mulut-Tetha60', 'mulut-Magnitude60', 'mulut-X61', 'mulut-Y61', 'mulut-Tetha61', 'mulut-Magnitude61', 'mulut-X62', 'mulut-Y62', 'mulut-Tetha62', 'mulut-Magnitude62', 'mulut-X63', 'mulut-Y63', 'mulut-Tetha63', 'mulut-Magnitude63', 'mulut-X64', 'mulut-Y64', 'mulut-Tetha64', 'mulut-Magnitude64', 'mulut-X65', 'mulut-Y65', 'mulut-Tetha65', 'mulut-Magnitude65', 'mulut-X66', 'mulut-Y66', 'mulut-Tetha66', 'mulut-Magnitude66', 'mulut-X67', 'mulut-Y67', 'mulut-Tetha67', 'mulut-Magnitude67', 'mulut-X68', 'mulut-Y68', 'mulut-Tetha68', 'mulut-Magnitude68', 'mulut-X69', 'mulut-Y69', 'mulut-Tetha69', 'mulut-Magnitude69', 'mulut-X70', 'mulut-Y70', 'mulut-Tetha70', 'mulut-Magnitude70', 'mulut-X71', 'mulut-Y71', 'mulut-Tetha71', 'mulut-Magnitude71', 'mulut-X72', 'mulut-Y72', 'mulut-Tetha72', 'mulut-Magnitude72', 'mulut-X73', 'mulut-Y73', 'mulut-Tetha73', 'mulut-Magnitude73', 'mulut-X74', 'mulut-Y74', 'mulut-Tetha74', 'mulut-Magnitude74', 'mulut-X75', 'mulut-Y75', 'mulut-Tetha75', 'mulut-Magnitude75', 'mulut-X76', 'mulut-Y76', 'mulut-Tetha76', 'mulut-Magnitude76', 'mulut-X77', 'mulut-Y77', 'mulut-Tetha77', 'mulut-Magnitude77', 'mulut-X78', 'mulut-Y78', 'mulut-Tetha78', 'mulut-Magnitude78', 'mulut-X79', 'mulut-Y79', 'mulut-Tetha79', 'mulut-Magnitude79', 'mulut-X80', 'mulut-Y80', 'mulut-Tetha80', 'mulut-Magnitude80', 'mulut-X81', 'mulut-Y81', 'mulut-Tetha81', 'mulut-Magnitude81', 'mulut-X82', 'mulut-Y82', 'mulut-Tetha82', 'mulut-Magnitude82', 'mulut-X83', 'mulut-Y83', 'mulut-Tetha83', 'mulut-Magnitude83', 'mulut-X84', 'mulut-Y84', 'mulut-Tetha84', 'mulut-Magnitude84', 'mulut-X85', 'mulut-Y85', 'mulut-Tetha85', 'mulut-Magnitude85', 'mulut-X86', 'mulut-Y86', 'mulut-Tetha86', 'mulut-Magnitude86', 'mulut-X87', 'mulut-Y87', 'mulut-Tetha87', 'mulut-Magnitude87', 'mulut-X88', 'mulut-Y88', 'mulut-Tetha88', 'mulut-Magnitude88', 'mulut-X89', 'mulut-Y89', 'mulut-Tetha89', 'mulut-Magnitude89', 'mulut-X90', 'mulut-Y90', 'mulut-Tetha90', 'mulut-Magnitude90', 'mulut-X91', 'mulut-Y91', 'mulut-Tetha91', 'mulut-Magnitude91', 'mulut-X92', 'mulut-Y92', 'mulut-Tetha92', 'mulut-Magnitude92', 'mulut-X93', 'mulut-Y93', 'mulut-Tetha93', 'mulut-Magnitude93', 'mulut-X94', 'mulut-Y94', 'mulut-Tetha94', 'mulut-Magnitude94', 'mulut-X95', 'mulut-Y95', 'mulut-Tetha95', 'mulut-Magnitude95', 'mulut-X96', 'mulut-Y96', 'mulut-Tetha96', 'mulut-Magnitude96', 'mulut-X97', 'mulut-Y97', 'mulut-Tetha97', 'mulut-Magnitude97', 'mulut-X98', 'mulut-Y98', 'mulut-Tetha98', 'mulut-Magnitude98', 'mulut-X99', 'mulut-Y99', 'mulut-Tetha99', 'mulut-Magnitude99', 'mulut-X100', 'mulut-Y100', 'mulut-Tetha100', 'mulut-Magnitude100', 'alis-X1', 'alis-Y1', 'alis-Tetha1', 'alis-Magnitude1', 'alis-X2', 'alis-Y2', 'alis-Tetha2', 'alis-Magnitude2', 'alis-X3', 'alis-Y3', 'alis-Tetha3', 'alis-Magnitude3', 'alis-X4', 'alis-Y4', 'alis-Tetha4', 'alis-Magnitude4', 'alis-X5', 'alis-Y5', 'alis-Tetha5', 'alis-Magnitude5', 'alis-X6', 'alis-Y6', 'alis-Tetha6', 'alis-Magnitude6', 'alis-X7', 'alis-Y7', 'alis-Tetha7', 'alis-Magnitude7', 'alis-X8', 'alis-Y8', 'alis-Tetha8', 'alis-Magnitude8', 'alis-X9', 'alis-Y9', 'alis-Tetha9', 'alis-Magnitude9', 'alis-X10', 'alis-Y10', 'alis-Tetha10', 'alis-Magnitude10', 'alis-X11', 'alis-Y11', 'alis-Tetha11', 'alis-Magnitude11', 'alis-X12', 'alis-Y12', 'alis-Tetha12', 'alis-Magnitude12', 'alis-X13', 'alis-Y13', 'alis-Tetha13', 'alis-Magnitude13', 'alis-X14', 'alis-Y14', 'alis-Tetha14', 'alis-Magnitude14', 'alis-X15', 'alis-Y15', 'alis-Tetha15', 'alis-Magnitude15', 'alis-X16', 'alis-Y16', 'alis-Tetha16', 'alis-Magnitude16', 'alis-X17', 'alis-Y17', 'alis-Tetha17', 'alis-Magnitude17', 'alis-X18', 'alis-Y18', 'alis-Tetha18', 'alis-Magnitude18', 'alis-X19', 'alis-Y19', 'alis-Tetha19', 'alis-Magnitude19', 'alis-X20', 'alis-Y20', 'alis-Tetha20', 'alis-Magnitude20', 'alis-X21', 'alis-Y21', 'alis-Tetha21', 'alis-Magnitude21', 'alis-X22', 'alis-Y22', 'alis-Tetha22', 'alis-Magnitude22', 'alis-X23', 'alis-Y23', 'alis-Tetha23', 'alis-Magnitude23', 'alis-X24', 'alis-Y24', 'alis-Tetha24', 'alis-Magnitude24', 'alis-X25', 'alis-Y25', 'alis-Tetha25', 'alis-Magnitude25', 'alis-X26', 'alis-Y26', 'alis-Tetha26', 'alis-Magnitude26', 'alis-X27', 'alis-Y27', 'alis-Tetha27', 'alis-Magnitude27', 'alis-X28', 'alis-Y28', 'alis-Tetha28', 'alis-Magnitude28', 'alis-X29', 'alis-Y29', 'alis-Tetha29', 'alis-Magnitude29', 'alis-X30', 'alis-Y30', 'alis-Tetha30', 'alis-Magnitude30', 'alis-X31', 'alis-Y31', 'alis-Tetha31', 'alis-Magnitude31', 'alis-X32', 'alis-Y32', 'alis-Tetha32', 'alis-Magnitude32', 'alis-X33', 'alis-Y33', 'alis-Tetha33', 'alis-Magnitude33', 'alis-X34', 'alis-Y34', 'alis-Tetha34', 'alis-Magnitude34', 'alis-X35', 'alis-Y35', 'alis-Tetha35', 'alis-Magnitude35', 'alis-X36', 'alis-Y36', 'alis-Tetha36', 'alis-Magnitude36', 'alis-X37', 'alis-Y37', 'alis-Tetha37', 'alis-Magnitude37', 'alis-X38', 'alis-Y38', 'alis-Tetha38', 'alis-Magnitude38', 'alis-X39', 'alis-Y39', 'alis-Tetha39', 'alis-Magnitude39', 'alis-X40', 'alis-Y40', 'alis-Tetha40', 'alis-Magnitude40', 'alis-X41', 'alis-Y41', 'alis-Tetha41', 'alis-Magnitude41', 'alis-X42', 'alis-Y42', 'alis-Tetha42', 'alis-Magnitude42', 'alis-X43', 'alis-Y43', 'alis-Tetha43', 'alis-Magnitude43', 'alis-X44', 'alis-Y44', 'alis-Tetha44', 'alis-Magnitude44', 'alis-X45', 'alis-Y45', 'alis-Tetha45', 'alis-Magnitude45', 'alis-X46', 'alis-Y46', 'alis-Tetha46', 'alis-Magnitude46', 'alis-X47', 'alis-Y47', 'alis-Tetha47', 'alis-Magnitude47', 'alis-X48', 'alis-Y48', 'alis-Tetha48', 'alis-Magnitude48', 'alis-X49', 'alis-Y49', 'alis-Tetha49', 'alis-Magnitude49', 'alis-X50', 'alis-Y50', 'alis-Tetha50', 'alis-Magnitude50', 'alis-X51', 'alis-Y51', 'alis-Tetha51', 'alis-Magnitude51', 'alis-X52', 'alis-Y52', 'alis-Tetha52', 'alis-Magnitude52', 'alis-X53', 'alis-Y53', 'alis-Tetha53', 'alis-Magnitude53', 'alis-X54', 'alis-Y54', 'alis-Tetha54', 'alis-Magnitude54', 'alis-X55', 'alis-Y55', 'alis-Tetha55', 'alis-Magnitude55', 'alis-X56', 'alis-Y56', 'alis-Tetha56', 'alis-Magnitude56', 'alis-X57', 'alis-Y57', 'alis-Tetha57', 'alis-Magnitude57', 'alis-X58', 'alis-Y58', 'alis-Tetha58', 'alis-Magnitude58', 'alis-X59', 'alis-Y59', 'alis-Tetha59', 'alis-Magnitude59', 'alis-X60', 'alis-Y60', 'alis-Tetha60', 'alis-Magnitude60', 'alis-X61', 'alis-Y61', 'alis-Tetha61', 'alis-Magnitude61', 'alis-X62', 'alis-Y62', 'alis-Tetha62', 'alis-Magnitude62', 'alis-X63', 'alis-Y63', 'alis-Tetha63', 'alis-Magnitude63', 'alis-X64', 'alis-Y64', 'alis-Tetha64', 'alis-Magnitude64', 'alis-X65', 'alis-Y65', 'alis-Tetha65', 'alis-Magnitude65', 'alis-X66', 'alis-Y66', 'alis-Tetha66', 'alis-Magnitude66', 'alis-X67', 'alis-Y67', 'alis-Tetha67', 'alis-Magnitude67', 'alis-X68', 'alis-Y68', 'alis-Tetha68', 'alis-Magnitude68', 'alis-X69', 'alis-Y69', 'alis-Tetha69', 'alis-Magnitude69', 'alis-X70', 'alis-Y70', 'alis-Tetha70', 'alis-Magnitude70', 'alis-X71', 'alis-Y71', 'alis-Tetha71', 'alis-Magnitude71', 'alis-X72', 'alis-Y72', 'alis-Tetha72', 'alis-Magnitude72', 'alis-X73', 'alis-Y73', 'alis-Tetha73', 'alis-Magnitude73', 'alis-X74', 'alis-Y74', 'alis-Tetha74', 'alis-Magnitude74', 'alis-X75', 'alis-Y75', 'alis-Tetha75', 'alis-Magnitude75', 'alis-X76', 'alis-Y76', 'alis-Tetha76', 'alis-Magnitude76', 'alis-X77', 'alis-Y77', 'alis-Tetha77', 'alis-Magnitude77', 'alis-X78', 'alis-Y78', 'alis-Tetha78', 'alis-Magnitude78', 'alis-X79', 'alis-Y79', 'alis-Tetha79', 'alis-Magnitude79', 'alis-X80', 'alis-Y80', 'alis-Tetha80', 'alis-Magnitude80', 'alis-X81', 'alis-Y81', 'alis-Tetha81', 'alis-Magnitude81', 'alis-X82', 'alis-Y82', 'alis-Tetha82', 'alis-Magnitude82', 'alis-X83', 'alis-Y83', 'alis-Tetha83', 'alis-Magnitude83', 'alis-X84', 'alis-Y84', 'alis-Tetha84', 'alis-Magnitude84', 'alis-X85', 'alis-Y85', 'alis-Tetha85', 'alis-Magnitude85', 'alis-X86', 'alis-Y86', 'alis-Tetha86', 'alis-Magnitude86', 'alis-X87', 'alis-Y87', 'alis-Tetha87', 'alis-Magnitude87', 'alis-X88', 'alis-Y88', 'alis-Tetha88', 'alis-Magnitude88', 'alis-X89', 'alis-Y89', 'alis-Tetha89', 'alis-Magnitude89', 'alis-X90', 'alis-Y90', 'alis-Tetha90', 'alis-Magnitude90', 'alis-X91', 'alis-Y91', 'alis-Tetha91', 'alis-Magnitude91', 'alis-X92', 'alis-Y92', 'alis-Tetha92', 'alis-Magnitude92', 'alis-X93', 'alis-Y93', 'alis-Tetha93', 'alis-Magnitude93', 'alis-X94', 'alis-Y94', 'alis-Tetha94', 'alis-Magnitude94', 'alis-X95', 'alis-Y95', 'alis-Tetha95', 'alis-Magnitude95', 'alis-X96', 'alis-Y96', 'alis-Tetha96', 'alis-Magnitude96', 'alis-X97', 'alis-Y97', 'alis-Tetha97', 'alis-Magnitude97', 'alis-X98', 'alis-Y98', 'alis-Tetha98', 'alis-Magnitude98', 'alis-X99', 'alis-Y99', 'alis-Tetha99', 'alis-Magnitude99', 'alis-X100', 'alis-Y100', 'alis-Tetha100', 'alis-Magnitude100', 'alis-X101', 'alis-Y101', 'alis-Tetha101', 'alis-Magnitude101', 'alis-X102', 'alis-Y102', 'alis-Tetha102', 'alis-Magnitude102', 'alis-X103', 'alis-Y103', 'alis-Tetha103', 'alis-Magnitude103', 'alis-X104', 'alis-Y104', 'alis-Tetha104', 'alis-Magnitude104', 'alis-X105', 'alis-Y105', 'alis-Tetha105', 'alis-Magnitude105', 'alis-X106', 'alis-Y106', 'alis-Tetha106', 'alis-Magnitude106', 'alis-X107', 'alis-Y107', 'alis-Tetha107', 'alis-Magnitude107', 'alis-X108', 'alis-Y108', 'alis-Tetha108', 'alis-Magnitude108', 'alis-X109', 'alis-Y109', 'alis-Tetha109', 'alis-Magnitude109', 'alis-X110', 'alis-Y110', 'alis-Tetha110', 'alis-Magnitude110', 'alis-X111', 'alis-Y111', 'alis-Tetha111', 'alis-Magnitude111', 'alis-X112', 'alis-Y112', 'alis-Tetha112', 'alis-Magnitude112', 'alis-X113', 'alis-Y113', 'alis-Tetha113', 'alis-Magnitude113', 'alis-X114', 'alis-Y114', 'alis-Tetha114', 'alis-Magnitude114', 'alis-X115', 'alis-Y115', 'alis-Tetha115', 'alis-Magnitude115', 'alis-X116', 'alis-Y116', 'alis-Tetha116', 'alis-Magnitude116', 'alis-X117', 'alis-Y117', 'alis-Tetha117', 'alis-Magnitude117', 'alis-X118', 'alis-Y118', 'alis-Tetha118', 'alis-Magnitude118', 'alis-X119', 'alis-Y119', 'alis-Tetha119', 'alis-Magnitude119', 'alis-X120', 'alis-Y120', 'alis-Tetha120', 'alis-Magnitude120', 'alis-X121', 'alis-Y121', 'alis-Tetha121', 'alis-Magnitude121', 'alis-X122', 'alis-Y122', 'alis-Tetha122', 'alis-Magnitude122', 'alis-X123', 'alis-Y123', 'alis-Tetha123', 'alis-Magnitude123', 'alis-X124', 'alis-Y124', 'alis-Tetha124', 'alis-Magnitude124', 'alis-X125', 'alis-Y125', 'alis-Tetha125', 'alis-Magnitude125', 'alis-X126', 'alis-Y126', 'alis-Tetha126', 'alis-Magnitude126', 'alis-X127', 'alis-Y127', 'alis-Tetha127', 'alis-Magnitude127', 'alis-X128', 'alis-Y128', 'alis-Tetha128', 'alis-Magnitude128', 'alis-X129', 'alis-Y129', 'alis-Tetha129', 'alis-Magnitude129', 'alis-X130', 'alis-Y130', 'alis-Tetha130', 'alis-Magnitude130', 'alis-X131', 'alis-Y131', 'alis-Tetha131', 'alis-Magnitude131', 'alis-X132', 'alis-Y132', 'alis-Tetha132', 'alis-Magnitude132', 'alis-X133', 'alis-Y133', 'alis-Tetha133', 'alis-Magnitude133', 'alis-X134', 'alis-Y134', 'alis-Tetha134', 'alis-Magnitude134', 'alis-X135', 'alis-Y135', 'alis-Tetha135', 'alis-Magnitude135', 'alis-X136', 'alis-Y136', 'alis-Tetha136', 'alis-Magnitude136', 'alis-X137', 'alis-Y137', 'alis-Tetha137', 'alis-Magnitude137', 'alis-X138', 'alis-Y138', 'alis-Tetha138', 'alis-Magnitude138', 'alis-X139', 'alis-Y139', 'alis-Tetha139', 'alis-Magnitude139', 'alis-X140', 'alis-Y140', 'alis-Tetha140', 'alis-Magnitude140']\n",
      "     Frame       Folder Path   Label  mulut-X1  mulut-Y1  mulut-Tetha1  \\\n",
      "0  1(img1)  Abdul Aziz_clip1  Rendah       NaN       NaN           NaN   \n",
      "1  2(img2)  Abdul Aziz_clip1  Rendah       0.0       0.0           0.0   \n",
      "2  3(img3)  Abdul Aziz_clip1  Rendah       0.0       0.0           0.0   \n",
      "3  4(img4)  Abdul Aziz_clip1  Rendah       0.0       0.0           0.0   \n",
      "4  5(img5)  Abdul Aziz_clip1  Rendah       0.0       0.0           0.0   \n",
      "\n",
      "   mulut-Magnitude1  mulut-X2  mulut-Y2  mulut-Tetha2  ...  alis-Tetha138  \\\n",
      "0               NaN       NaN       NaN           NaN  ...            NaN   \n",
      "1               0.0       0.0       0.0           0.0  ...        225.000   \n",
      "2               0.0       0.0       0.0           0.0  ...        213.690   \n",
      "3               0.0       0.0       0.0           0.0  ...         90.000   \n",
      "4               0.0       0.0       0.0           0.0  ...         18.435   \n",
      "\n",
      "   alis-Magnitude138  alis-X139  alis-Y139  alis-Tetha139  alis-Magnitude139  \\\n",
      "0                NaN        NaN        NaN            NaN                NaN   \n",
      "1              1.414        0.0        1.0           90.0                1.0   \n",
      "2              3.606        0.0        0.0            0.0                0.0   \n",
      "3              2.000        0.0       -3.0          270.0                3.0   \n",
      "4              3.162        0.0        0.0            0.0                0.0   \n",
      "\n",
      "   alis-X140  alis-Y140  alis-Tetha140  alis-Magnitude140  \n",
      "0        NaN        NaN            NaN                NaN  \n",
      "1        0.0        1.0           90.0              1.000  \n",
      "2        0.0        0.0            0.0              0.000  \n",
      "3       -1.0        1.0          135.0              1.414  \n",
      "4        0.0        0.0            0.0              0.000  \n",
      "\n",
      "[5 rows x 963 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Baca file CSV dari folder relatif\n",
    "df = pd.read_csv('output-baru/csv/nilai-fitur-all-component.csv')\n",
    "\n",
    "# Tampilkan kolom dan data awal\n",
    "print(\"Kolom tersedia:\", df.columns.tolist())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total kolom: 963\n",
      "Jumlah fitur: 960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('output-baru/csv/nilai-fitur-all-component.csv')\n",
    "\n",
    "total_kolom = df.shape[1]\n",
    "\n",
    "# Hitung jumlah fitur (dengan asumsi 3 kolom pertama bukan fitur)\n",
    "jumlah_fitur = total_kolom - 3\n",
    "\n",
    "print(\"Total kolom:\", total_kolom)\n",
    "print(\"Jumlah fitur:\", jumlah_fitur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import shutil\n",
    "np.set_printoptions(threshold=np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekstraksi fitur selesai. Hasil telah disimpan di folder: output-baru\n"
     ]
    }
   ],
   "source": [
    "# Import module yang digunakan\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from preprocessing.scarpping_component import extract_component_by_images\n",
    "from feature_extraction.poc import POC\n",
    "from feature_extraction.vektor import Vektor\n",
    "from feature_extraction.quadran import Quadran\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n",
    "\n",
    "# load model dan shape predictor untuk deteksi wajah\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "components_setup = {\n",
    "    'mulut': {\n",
    "        'object_name': 'Mouth',\n",
    "        'object_rectangle': {\"x_right\": 54, \"x_left\": 48, \"y_highest\": 52, \"y_lowest\": 57},\n",
    "        'pixel_shifting': {\"pixel_x\": 25, \"pixel_y\": 10},\n",
    "        'object_dimension': {'width': 140, 'height': 40}\n",
    "    },\n",
    "    'alis': {\n",
    "        'object_name': 'Eyebrows',\n",
    "        'object_rectangle': {\"x_right\": 26, \"x_left\": 17, \"y_highest\": 18, \"y_lowest\": 25},\n",
    "        'pixel_shifting': {\"pixel_x\": 20, \"pixel_y\": 15},\n",
    "        'object_dimension': {'width': 200, 'height': 40}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Inisialisasi variabel untuk path url dan blok size\n",
    "blockSize = 7\n",
    "pathDirectory = {\n",
    "    \"base_path_dataset\": \"dataset\",\n",
    "    \"base_dataset_input\": \"dataset/training_images\",\n",
    "    \"result_dataset\": \"output-baru\", \n",
    "    \"component_image\": \"component_to_images\", \n",
    "    \"video_frame\": \"video_to_images\"\n",
    "}\n",
    "\n",
    "# Inisialisasi variabel untuk menyimpan data dari masing-masing komponen\n",
    "frames_data = {component_name: [] for component_name in components_setup}\n",
    "total_blocks_components = {component_name: 0 for component_name in components_setup}\n",
    "data_blocks_first_image = {component_name: None for component_name in components_setup}\n",
    "index = {component_name: 0 for component_name in components_setup}\n",
    "\n",
    "# Hitung total blok dari masing-masing komponen lalu disetup kedalam total_blocks_components\n",
    "for component_name, component_info in components_setup.items():\n",
    "    total_blocks_components[component_name] = int((component_info['object_dimension']['width'] / blockSize) * (component_info['object_dimension']['height'] / blockSize))\n",
    "\n",
    "# Loop melalui setiap kunci dan nilai di pathDirectory dan hapus direktorinya\n",
    "for key, value in pathDirectory.items():\n",
    "    # Jika tidak mengandung base, hapus direktori sesuai dengan nilai yang ada\n",
    "    if not \"base\" in key:\n",
    "        shutil.rmtree(value, ignore_errors=True)\n",
    "\n",
    "# Looping folder label didalam base_dataset_input\n",
    "for foldername_label in os.listdir(pathDirectory['base_dataset_input']):\n",
    "    foldername_label_join_basepath = os.path.join(pathDirectory['base_dataset_input'], foldername_label)\n",
    "    # Jika folder nya tidak ada skip looping ini\n",
    "    if not os.path.isdir(foldername_label_join_basepath):\n",
    "        continue\n",
    "    \n",
    "    # Looping folder label didalam foldername_label_join_basepath \n",
    "    for foldername in os.listdir(foldername_label_join_basepath):\n",
    "        foldername_join_basepath = os.path.join(foldername_label_join_basepath, foldername)\n",
    "        # Jika folder nya tidak ada skip looping ini\n",
    "        if not os.path.isdir(foldername_join_basepath):\n",
    "            continue\n",
    "\n",
    "        # Reset variabel setiap kali mulai looping folder baru\n",
    "        data_blocks_first_image = {component_name: None for component_name in components_setup}\n",
    "        index = {component_name: 0 for component_name in components_setup}\n",
    "\n",
    "        # looping semua file yang ada didalam\n",
    "        for filename in sorted(os.listdir(foldername_join_basepath), key=natural_sort_key):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "\n",
    "                # Read path sesuai dengan foldername_join_basepath dijoin path dengan filename\n",
    "                image = cv2.imread(os.path.join(foldername_join_basepath, filename))\n",
    "                # Convert image ke grayscale\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Deteksi shape muka didalam grayscale image\n",
    "                rects = detector(gray)\n",
    "\n",
    "                # Memproses rects untuk setiap bentuk wajah yang terdeteksi\n",
    "                for rect in rects:\n",
    "                    # Ambil bentuk wajah dalam bentuk shape sesuai dengan model predictor\n",
    "                    shape = predictor(gray, rect)\n",
    "                    # Memproses setiap komponen wajah\n",
    "                    for component_name, component_info in components_setup.items():\n",
    "                        # Buat variabel frame_data untuk menampung data current frame\n",
    "                        frame_data = {'Frame': f\"{index[component_name] + 1}({filename.split('.')[0]})\"}\n",
    "\n",
    "                        # Ambil data blok image dari return fungsi extract_component_by_images\n",
    "                        data_blocks_image_current = extract_component_by_images(\n",
    "                            image=image,\n",
    "                            shape=shape,\n",
    "                            frameName=filename.split(\".\")[0],\n",
    "                            objectName=component_info['object_name'],\n",
    "                            objectRectangle=component_info['object_rectangle'],\n",
    "                            pixelShifting=component_info['pixel_shifting'],\n",
    "                            objectDimension=component_info['object_dimension']\n",
    "                        )\n",
    "                        \n",
    "                        # Ambil frame pertama dari perulangan lalu simpan di variabel dan skip (lanjutkan ke frame berikut)\n",
    "                        if data_blocks_first_image[component_name] is None:\n",
    "                            # Append data frame ke list frames_data sesuai dengan component_name\n",
    "                            frames_data[component_name].append(frame_data)\n",
    "                            # Tambahkan kolom \"Folder Path\" dengan nilai folder saat ini\n",
    "                            frame_data['Folder Path'] = foldername\n",
    "                            # Tambahkan kolom \"Label\" dengan nilai label saat ini\n",
    "                            frame_data['Label'] = foldername_label\n",
    "                            # Set value data_blocks_first_image[component_name] ke data_blocks_image_current\n",
    "                            data_blocks_first_image[component_name] = data_blocks_image_current\n",
    "                            # Skip looping nya ke looping selanjutnya\n",
    "                            continue\n",
    "\n",
    "                        # Inisiasi class POC\n",
    "                        initPOC = POC(data_blocks_first_image[component_name], data_blocks_image_current, blockSize) \n",
    "                        # Pemanggilan fungsi pocCalc() untuk menghitung nilai POC disetiap gambar\n",
    "                        valPOC = initPOC.getPOC() \n",
    "\n",
    "                        # Pemanggilan class dan method untuk menampilkan quiver / gambar panah\n",
    "                        initQuiv = Vektor(valPOC, blockSize)\n",
    "                        quivData = initQuiv.getVektor() \n",
    "\n",
    "                        # Pemanggilan class untuk mengeluarkan nilai karakteristik vektor\n",
    "                        initQuadran = Quadran(quivData) \n",
    "                        quadran = initQuadran.getQuadran()\n",
    "\n",
    "                        # Update frame_data dengan data quadran\n",
    "                        for i, quad in enumerate(quadran):\n",
    "                            # Set data kedalam frame_data sesuai column nya\n",
    "                            frame_data[f'X{i+1}'] = quad[1]\n",
    "                            frame_data[f'Y{i+1}'] = quad[2]\n",
    "                            frame_data[f'Tetha{i+1}'] = quad[3]\n",
    "                            frame_data[f'Magnitude{i+1}'] = quad[4]\n",
    "                        \n",
    "                        # Append data frame ke list\n",
    "                        frames_data[component_name].append(frame_data)\n",
    "                        # Tambahkan kolom \"Folder Path\" dengan nilai folder saat ini\n",
    "                        frame_data['Folder Path'] = foldername\n",
    "                        # Tambahkan kolom \"Label\" dengan nilai label saat ini\n",
    "                        frame_data['Label'] = foldername_label\n",
    "\n",
    "                # Update index per component_name\n",
    "                index[component_name] += 1\n",
    "\n",
    "# Membuat direktori jika belum ada untuk outputnya\n",
    "output_csv_dir = os.path.join(pathDirectory['result_dataset'], 'csv')\n",
    "output_excel_dir = os.path.join(pathDirectory['result_dataset'], 'excel')\n",
    "os.makedirs(output_csv_dir, exist_ok=True)\n",
    "os.makedirs(output_excel_dir, exist_ok=True)\n",
    "\n",
    "# Hapus file output dari semua tipe dataset baik csv dan xlsx jika ada (Nilai fitur)\n",
    "for component_name in components_setup:\n",
    "    csv_file_path = os.path.join(output_csv_dir, f'{component_name}.csv')\n",
    "    xlsx_file_path = os.path.join(output_excel_dir, f'{component_name}.xlsx')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        os.remove(csv_file_path)\n",
    "    if os.path.exists(xlsx_file_path):\n",
    "        os.remove(xlsx_file_path)\n",
    "\n",
    "# Export dataframe ke dalam file csv dan xlsx sesuai dengan masing-masing component untuk fitur ekstrasi biasa\n",
    "for component_name, data_frame in frames_data.items():\n",
    "    # Initialisasi dataframe dengan pandas\n",
    "    df = pd.DataFrame(data_frame)\n",
    "    \n",
    "    # Simpan ke file CSV\n",
    "    nama_file_csv = f'{output_csv_dir}/{component_name}.csv'\n",
    "    df.to_csv(nama_file_csv, index=False, float_format=None)\n",
    "    \n",
    "    # Simpan ke file Excel\n",
    "    nama_file_xlsx = f'{output_excel_dir}/{component_name}.xlsx'\n",
    "    df.to_excel(nama_file_xlsx, index=False, float_format=None)\n",
    "\n",
    "# Export dataframe untuk semua komponen digabung\n",
    "frames_data_all_components = []\n",
    "\n",
    "# Gabungkan semua data frame dari semua komponen\n",
    "for component_name, data_frames in frames_data.items():\n",
    "    for i, frame in enumerate(data_frames):\n",
    "        if i >= len(frames_data_all_components):\n",
    "            frames_data_all_components.append({})\n",
    "        \n",
    "        # Tambahkan prefix nama komponen ke nama kolom\n",
    "        for key, value in frame.items():\n",
    "            if key not in ['Frame', 'Folder Path', 'Label']:\n",
    "                frames_data_all_components[i][f'{component_name}-{key}'] = value\n",
    "            else:\n",
    "                frames_data_all_components[i][key] = value\n",
    "\n",
    "# Initialisasi dataframe dengan pandas untuk semua komponen\n",
    "df_all = pd.DataFrame(frames_data_all_components)\n",
    "\n",
    "# Inisialisasi nama file untuk dataset semua komponen\n",
    "nama_file_csv = f'{output_csv_dir}/nilai-fitur-all-component.csv'\n",
    "nama_file_xlsx = f'{output_excel_dir}/nilai-fitur-all-component.xlsx'\n",
    "\n",
    "# Hapus file output jika sudah ada\n",
    "if os.path.exists(nama_file_csv):\n",
    "    os.remove(nama_file_csv)\n",
    "if os.path.exists(nama_file_xlsx):\n",
    "    os.remove(nama_file_xlsx)\n",
    "\n",
    "# Simpan ke file CSV dan Excel\n",
    "df_all.to_csv(nama_file_csv, index=False, float_format=None)\n",
    "df_all.to_excel(nama_file_xlsx, index=False, float_format=None)\n",
    "\n",
    "print(\"Ekstraksi fitur selesai. Hasil telah disimpan di folder:\", pathDirectory['result_dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample saved successfully at output-baru\\mouth_regions\\samples\\sample_Tinggi_img1.jpg\n",
      "\n",
      "=== Processing category: Tinggi ===\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def extract_mouth_region(image_path, face_predictor_path=\"models/shape_predictor_68_face_landmarks.dat\", padding_x=10, padding_y=10, target_size=(100, 50)):\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"File tidak ditemukan: {image_path}\")\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Tidak dapat membaca gambar dari {image_path}\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if not os.path.exists(face_predictor_path):\n",
    "        raise FileNotFoundError(f\"File predictor tidak ditemukan: {face_predictor_path}\")\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(face_predictor_path)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    if len(faces) == 0:\n",
    "        raise ValueError(\"Tidak ada wajah yang terdeteksi dalam gambar\")\n",
    "\n",
    "    face = faces[0]\n",
    "    landmarks = predictor(gray, face)\n",
    "    landmarks_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(68)]\n",
    "\n",
    "    mouth_points = landmarks_points[48:68]\n",
    "    x_coordinates = [p[0] for p in mouth_points]\n",
    "    y_coordinates = [p[1] for p in mouth_points]\n",
    "\n",
    "    left = max(0, min(x_coordinates) - padding_x)\n",
    "    top = max(0, min(y_coordinates) - padding_y)\n",
    "    right = min(image.shape[1], max(x_coordinates) + padding_x)\n",
    "    bottom = min(image.shape[0], max(y_coordinates) + padding_y)\n",
    "\n",
    "    mouth_region = image[top:bottom, left:right]\n",
    "    mouth_region_resized = cv2.resize(mouth_region, target_size)\n",
    "    return mouth_region_resized, (left, top, right, bottom)\n",
    "\n",
    "paths = {\n",
    "    \"base_path_dataset\": \"dataset\",\n",
    "    \"base_dataset_input\": \"dataset/training_images\",\n",
    "    \"result_dataset\": \"output-baru\",\n",
    "    \"component_image\": \"component_to_images\",\n",
    "    \"video_frame\": \"video_to_images\",\n",
    "    \"mouth_output\": \"mouth_regions\"\n",
    "}\n",
    "\n",
    "categories = [\"Tinggi\", \"Rendah\", \"Sangat tinggi\", \"Sangat rendah\"]\n",
    "\n",
    "def ensure_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(paths[\"base_path_dataset\"]):\n",
    "        print(f\"ERROR: Base dataset path not found: {paths['base_path_dataset']}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not os.path.exists(paths[\"base_dataset_input\"]):\n",
    "        print(f\"ERROR: Input images path not found: {paths['base_dataset_input']}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    category_paths = {}\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(paths[\"base_dataset_input\"], category)\n",
    "        if os.path.exists(category_path):\n",
    "            category_paths[category] = category_path\n",
    "        else:\n",
    "            print(f\"WARNING: Category folder not found: {category_path}\")\n",
    "\n",
    "    if not category_paths:\n",
    "        print(\"ERROR: No valid category folders found!\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    face_predictor_path = \"models/shape_predictor_68_face_landmarks.dat\"\n",
    "    if not os.path.exists(face_predictor_path):\n",
    "        print(f\"ERROR: Face predictor file not found: {face_predictor_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    def process_sample_image():\n",
    "        for category, path in category_paths.items():\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                sample_files = [f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "                if sample_files:\n",
    "                    sample_file = sample_files[0]\n",
    "                    sample_path = os.path.join(root, sample_file)\n",
    "                    sample_output_dir = os.path.join(paths[\"result_dataset\"], paths[\"mouth_output\"], \"samples\")\n",
    "                    ensure_directory(sample_output_dir)\n",
    "                    output_path = os.path.join(sample_output_dir, f\"sample_{category}_{sample_file}\")\n",
    "                    try:\n",
    "                        mouth_region, bbox = extract_mouth_region(sample_path, face_predictor_path)\n",
    "                        if cv2.imwrite(output_path, mouth_region):\n",
    "                            print(f\"Sample saved successfully at {output_path}\")\n",
    "                            return True\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing sample: {e}\")\n",
    "        return False\n",
    "\n",
    "    def process_all_images():\n",
    "        processed_count = 0\n",
    "        error_count = 0\n",
    "        for category, category_path in category_paths.items():\n",
    "            print(f\"\\n=== Processing category: {category} ===\")\n",
    "            category_output_dir = os.path.join(paths[\"result_dataset\"], paths[\"mouth_output\"], category)\n",
    "            ensure_directory(category_output_dir)\n",
    "            image_files = []\n",
    "            for root, dirs, files in os.walk(category_path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                        image_files.append(os.path.join(root, file))\n",
    "            for i, image_path in enumerate(image_files):\n",
    "                filename = os.path.basename(image_path)\n",
    "                output_filename = f\"mouth_{os.path.splitext(filename)[0]}.jpg\"\n",
    "                output_path = os.path.join(category_output_dir, output_filename)\n",
    "                try:\n",
    "                    mouth_region, bbox = extract_mouth_region(image_path, face_predictor_path)\n",
    "                    if cv2.imwrite(output_path, mouth_region):\n",
    "                        processed_count += 1\n",
    "                    else:\n",
    "                        print(f\"Failed to save image {output_filename}\")\n",
    "                        error_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "                    error_count += 1\n",
    "        print(f\"\\nProcessing complete. Processed: {processed_count}, Errors: {error_count}\")\n",
    "\n",
    "    if process_sample_image():\n",
    "        process_all_images()\n",
    "    else:\n",
    "        user_input = input(\"Sample failed. Continue processing all images? (y/n): \")\n",
    "        if user_input.lower() == 'y':\n",
    "            process_all_images()\n",
    "        else:\n",
    "            print(\"Exiting program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: alis.csv contains 86240 NaN values. Imputing missing values.\n",
      "PCA Results for alis.csv:\n",
      "  Original Features: 560\n",
      "  Reduced Features: 405\n",
      "  Cumulative Explained Variance: 95.04%\n",
      "  Classification Accuracy: 93.34%\n",
      "  Output saved to: output-baru/pca_results\\pca_alis.csv\n",
      "\n",
      "  Original Features Accuracy: 99.08%\n",
      "  Accuracy Difference: -5.74%\n",
      "\n",
      "Warning: mulut.csv contains 61600 NaN values. Imputing missing values.\n",
      "PCA Results for mulut.csv:\n",
      "  Original Features: 400\n",
      "  Reduced Features: 290\n",
      "  Cumulative Explained Variance: 95.02%\n",
      "  Classification Accuracy: 88.62%\n",
      "  Output saved to: output-baru/pca_results\\pca_mulut.csv\n",
      "\n",
      "  Original Features Accuracy: 98.57%\n",
      "  Accuracy Difference: -9.95%\n",
      "\n",
      "Warning: nilai-fitur-all-component.csv contains 147840 NaN values. Imputing missing values.\n",
      "PCA Results for nilai-fitur-all-component.csv:\n",
      "  Original Features: 960\n",
      "  Reduced Features: 689\n",
      "  Cumulative Explained Variance: 95.03%\n",
      "  Classification Accuracy: 96.35%\n",
      "  Output saved to: output-baru/pca_results\\pca_nilai-fitur-all-component.csv\n",
      "\n",
      "  Original Features Accuracy: 99.38%\n",
      "  Accuracy Difference: -3.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def perform_pca_feature_selection(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Perform PCA feature selection on CSV files in the input directory\n",
    "    and evaluate classification accuracy\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        Directory containing input CSV files\n",
    "    output_dir : str\n",
    "        Directory to save PCA results\n",
    "    \"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files in the input directory\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # Full path to the CSV file\n",
    "            input_path = os.path.join(input_dir, csv_file)\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(input_path)\n",
    "            \n",
    "            # Check for NaN values and print summary\n",
    "            nan_count = df.isna().sum().sum()\n",
    "            if nan_count > 0:\n",
    "                print(f\"Warning: {csv_file} contains {nan_count} NaN values. Imputing missing values.\")\n",
    "                \n",
    "            # Remove non-numeric columns for PCA\n",
    "            numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "            X = df[numeric_columns]\n",
    "            \n",
    "            # Separate features from metadata columns\n",
    "            metadata_columns = []\n",
    "            for col in ['Frame', 'Folder Path']:\n",
    "                if col in df.columns:\n",
    "                    metadata_columns.append(col)\n",
    "                    \n",
    "            label_column = 'Label'\n",
    "            \n",
    "            # Check if label column exists in the DataFrame\n",
    "            if label_column not in df.columns:\n",
    "                print(f\"Warning: '{label_column}' column not found in {csv_file}. Skipping accuracy calculation.\")\n",
    "                continue\n",
    "                \n",
    "            metadata = df[metadata_columns] if metadata_columns else pd.DataFrame()\n",
    "            y = df[label_column]\n",
    "            \n",
    "            # Handle missing values with SimpleImputer\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_imputed = imputer.fit_transform(X)\n",
    "            \n",
    "            # Standardize the features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_imputed)\n",
    "            \n",
    "            # Perform PCA\n",
    "            # We'll use 95% explained variance as our criteria\n",
    "            pca = PCA(n_components=0.95)\n",
    "            X_pca = pca.fit_transform(X_scaled)\n",
    "            \n",
    "            # Create a DataFrame with PCA results\n",
    "            pca_columns = [f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
    "            df_pca = pd.DataFrame(X_pca, columns=pca_columns)\n",
    "            \n",
    "            # Add back the metadata columns and label\n",
    "            if not metadata.empty:\n",
    "                df_pca = pd.concat([metadata, df_pca], axis=1)\n",
    "            df_pca[label_column] = y\n",
    "            \n",
    "            # Plot explained variance ratio\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "                    pca.explained_variance_ratio_)\n",
    "            plt.xlabel('Principal Components')\n",
    "            plt.ylabel('Explained Variance Ratio')\n",
    "            plt.title(f'PCA Explained Variance - {csv_file}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'pca_variance_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Save PCA results\n",
    "            output_csv = os.path.join(output_dir, f'pca_{csv_file}')\n",
    "            df_pca.to_csv(output_csv, index=False)\n",
    "            \n",
    "            # Calculate accuracy using a classifier (RandomForest)\n",
    "            # Split data into training and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_pca, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "            )\n",
    "            \n",
    "            # Train a classifier\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Generate and save classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_csv(os.path.join(output_dir, f'classification_report_{csv_file}'))\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"PCA Results for {csv_file}:\")\n",
    "            print(f\"  Original Features: {X.shape[1]}\")\n",
    "            print(f\"  Reduced Features: {X_pca.shape[1]}\")\n",
    "            print(f\"  Cumulative Explained Variance: {pca.explained_variance_ratio_.sum() * 100:.2f}%\")\n",
    "            print(f\"  Classification Accuracy: {accuracy * 100:.2f}%\")\n",
    "            print(f\"  Output saved to: {output_csv}\\n\")\n",
    "            \n",
    "            # Compare with original features accuracy\n",
    "            clf_original = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
    "                X_scaled, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "            )\n",
    "            clf_original.fit(X_train_orig, y_train_orig)\n",
    "            y_pred_orig = clf_original.predict(X_test_orig)\n",
    "            accuracy_orig = accuracy_score(y_test_orig, y_pred_orig)\n",
    "            \n",
    "            print(f\"  Original Features Accuracy: {accuracy_orig * 100:.2f}%\")\n",
    "            print(f\"  Accuracy Difference: {(accuracy - accuracy_orig) * 100:.2f}%\\n\")\n",
    "            \n",
    "            # Plot accuracy comparison\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.bar(['Original Features', 'PCA Features'], [accuracy_orig, accuracy], color=['blue', 'orange'])\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Accuracy Comparison - {csv_file}')\n",
    "            plt.ylim(0, 1.1)\n",
    "            for i, v in enumerate([accuracy_orig, accuracy]):\n",
    "                plt.text(i, v + 0.05, f'{v:.2%}', ha='center')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'accuracy_comparison_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Directories for input and output\n",
    "input_dir = 'output-baru/csv'  # Update this to match your directory structure\n",
    "output_dir = 'output-baru/pca_results'\n",
    "\n",
    "# Run PCA feature selection with accuracy measurement\n",
    "perform_pca_feature_selection(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: alis.csv contains 86240 NaN values. Imputing missing values.\n",
      "RFE Results for alis.csv:\n",
      "  Original Features: 560\n",
      "  Selected Features: 280\n",
      "  Selected Feature Names: ['Tetha1', 'Magnitude1', 'X2', 'Tetha2', 'Magnitude2', 'Tetha3', 'Magnitude3', 'Tetha4', 'Magnitude4', 'Tetha5', 'Magnitude5', 'Tetha6', 'Magnitude6', 'Tetha7', 'Magnitude7', 'X8', 'Tetha8', 'Magnitude8', 'Tetha9', 'Magnitude9', 'Tetha10', 'Magnitude10', 'Tetha11', 'Magnitude11', 'Tetha12', 'Magnitude12', 'Tetha13', 'Magnitude13', 'Tetha14', 'Magnitude14', 'Y15', 'Tetha15', 'Magnitude15', 'Tetha16', 'Magnitude16', 'Tetha17', 'Magnitude17', 'Tetha18', 'Magnitude18', 'Tetha19', 'Magnitude19', 'Tetha20', 'Magnitude20', 'X21', 'Tetha21', 'Magnitude21', 'Y22', 'Tetha22', 'Magnitude22', 'Tetha23', 'Magnitude23', 'Tetha24', 'Magnitude24', 'Tetha25', 'Magnitude25', 'Tetha26', 'Magnitude26', 'Tetha27', 'Magnitude27', 'Tetha28', 'Magnitude28', 'Tetha29', 'Magnitude29', 'X30', 'Tetha30', 'Magnitude30', 'Magnitude31', 'Magnitude32', 'Magnitude33', 'Tetha34', 'Magnitude34', 'Tetha35', 'Magnitude35', 'Tetha36', 'Magnitude36', 'Tetha37', 'Magnitude37', 'Tetha38', 'Magnitude38', 'Tetha39', 'Magnitude39', 'Tetha40', 'Magnitude40', 'Tetha41', 'Magnitude41', 'Magnitude42', 'Tetha43', 'Magnitude43', 'Tetha44', 'Magnitude44', 'Tetha45', 'Magnitude45', 'Tetha46', 'Magnitude46', 'Y47', 'Tetha47', 'Magnitude47', 'Tetha48', 'Magnitude48', 'X49', 'Tetha49', 'Magnitude49', 'X50', 'Tetha50', 'Magnitude50', 'Tetha51', 'Magnitude51', 'Tetha52', 'Magnitude52', 'Tetha53', 'Magnitude53', 'Tetha54', 'Magnitude54', 'Tetha55', 'Magnitude55', 'Tetha56', 'Magnitude56', 'X57', 'Tetha57', 'Magnitude57', 'Tetha58', 'Magnitude58', 'X59', 'Tetha59', 'Magnitude59', 'Y60', 'Tetha60', 'Magnitude60', 'Magnitude64', 'Magnitude65', 'Tetha66', 'Magnitude66', 'Tetha67', 'Magnitude67', 'Tetha68', 'Magnitude68', 'Tetha70', 'Magnitude70', 'Tetha71', 'Magnitude71', 'Tetha72', 'Magnitude72', 'Magnitude73', 'Tetha74', 'Magnitude74', 'X75', 'Tetha75', 'Magnitude75', 'Tetha76', 'Magnitude76', 'X77', 'Tetha77', 'Magnitude77', 'Tetha78', 'Magnitude78', 'X79', 'Tetha79', 'Magnitude79', 'X80', 'Tetha80', 'Magnitude80', 'Tetha81', 'Magnitude81', 'Tetha82', 'Magnitude82', 'Tetha83', 'Magnitude83', 'Tetha84', 'Magnitude84', 'X85', 'Y85', 'Tetha85', 'Magnitude85', 'Tetha86', 'Magnitude86', 'Magnitude87', 'Tetha88', 'Magnitude88', 'Magnitude89', 'Tetha90', 'Magnitude90', 'Tetha91', 'Magnitude91', 'Magnitude92', 'Tetha93', 'Magnitude93', 'Tetha94', 'Magnitude94', 'Tetha95', 'Magnitude95', 'Y96', 'Tetha96', 'Magnitude96', 'X97', 'Magnitude97', 'Magnitude99', 'Tetha100', 'Magnitude100', 'X101', 'Magnitude101', 'X102', 'Tetha102', 'Magnitude102', 'Y103', 'Tetha103', 'Magnitude103', 'Tetha104', 'Magnitude104', 'X105', 'Y105', 'Tetha105', 'Magnitude105', 'X106', 'Y106', 'Tetha106', 'Magnitude106', 'X107', 'Tetha107', 'Magnitude107', 'X108', 'Tetha108', 'Magnitude108', 'Tetha109', 'Magnitude109', 'Tetha110', 'Magnitude110', 'Tetha111', 'Magnitude111', 'Tetha112', 'Magnitude112', 'X113', 'Tetha113', 'Magnitude113', 'X114', 'Magnitude114', 'Tetha115', 'Magnitude115', 'Magnitude119', 'Magnitude120', 'Magnitude121', 'Tetha122', 'Magnitude122', 'Magnitude123', 'Magnitude124', 'Tetha125', 'Magnitude125', 'Tetha126', 'Magnitude126', 'Tetha127', 'Magnitude127', 'Magnitude128', 'X129', 'Magnitude129', 'Y130', 'Tetha130', 'Magnitude130', 'X131', 'Tetha131', 'Magnitude131', 'X132', 'Y132', 'Tetha132', 'Magnitude132', 'X133', 'Tetha133', 'Magnitude133', 'Tetha134', 'Magnitude134', 'Tetha135', 'Magnitude135', 'Tetha136', 'Magnitude136', 'Tetha137', 'Magnitude137', 'Tetha138', 'Magnitude138', 'Tetha139', 'Magnitude139', 'Tetha140', 'Magnitude140']\n",
      "  Classification Accuracy with RFE: 99.18%\n",
      "  Original Features Accuracy: 99.08%\n",
      "  Accuracy Difference: 0.09%\n",
      "  Output saved to: output-baru/rfe_results\\rfe_alis.csv\n",
      "\n",
      "Warning: mulut.csv contains 61600 NaN values. Imputing missing values.\n",
      "RFE Results for mulut.csv:\n",
      "  Original Features: 400\n",
      "  Selected Features: 280\n",
      "  Selected Feature Names: ['X1', 'Tetha1', 'Magnitude1', 'Y2', 'Tetha2', 'Magnitude2', 'X3', 'Y3', 'Tetha3', 'Magnitude3', 'Tetha4', 'Magnitude4', 'Tetha5', 'Magnitude5', 'Tetha6', 'Magnitude6', 'X7', 'Y7', 'Tetha7', 'Magnitude7', 'Tetha8', 'Magnitude8', 'Tetha9', 'Magnitude9', 'Tetha10', 'Magnitude10', 'Tetha11', 'Magnitude11', 'Tetha12', 'Magnitude12', 'Tetha13', 'Magnitude13', 'X14', 'Tetha14', 'Magnitude14', 'X15', 'Tetha15', 'Magnitude15', 'Tetha16', 'Magnitude16', 'X17', 'Y17', 'Tetha17', 'Magnitude17', 'X18', 'Tetha18', 'Magnitude18', 'X19', 'Y19', 'Tetha19', 'Magnitude19', 'X20', 'Y20', 'Tetha20', 'Magnitude20', 'X21', 'Tetha21', 'Magnitude21', 'X22', 'Y22', 'Tetha22', 'Magnitude22', 'Tetha23', 'Magnitude23', 'Magnitude25', 'Y26', 'Tetha26', 'Magnitude26', 'Tetha27', 'Magnitude27', 'Y28', 'Tetha28', 'Magnitude28', 'Tetha29', 'Magnitude29', 'X30', 'Tetha30', 'Magnitude30', 'Tetha31', 'Magnitude31', 'Tetha32', 'Magnitude32', 'Tetha33', 'Magnitude33', 'X34', 'Tetha34', 'Magnitude34', 'X35', 'Y35', 'Tetha35', 'Magnitude35', 'Y36', 'Tetha36', 'Magnitude36', 'X37', 'Y37', 'Tetha37', 'Magnitude37', 'X38', 'Y38', 'Tetha38', 'Magnitude38', 'Y39', 'Tetha39', 'Magnitude39', 'X40', 'Y40', 'Tetha40', 'Magnitude40', 'Y41', 'Tetha41', 'Magnitude41', 'Tetha42', 'Magnitude42', 'Y43', 'Tetha43', 'Magnitude43', 'Tetha46', 'Magnitude46', 'X47', 'Y47', 'Tetha47', 'Magnitude47', 'Y48', 'Tetha48', 'Magnitude48', 'Y49', 'Tetha49', 'Magnitude49', 'Tetha51', 'Magnitude51', 'X52', 'Tetha52', 'Magnitude52', 'X53', 'Tetha53', 'Magnitude53', 'X54', 'Tetha54', 'Magnitude54', 'X55', 'Y55', 'Tetha55', 'Magnitude55', 'X56', 'Y56', 'Tetha56', 'Magnitude56', 'X57', 'Tetha57', 'Magnitude57', 'X58', 'Y58', 'Tetha58', 'Magnitude58', 'X59', 'Tetha59', 'Magnitude59', 'X60', 'Tetha60', 'Magnitude60', 'X61', 'Tetha61', 'Magnitude61', 'X62', 'Tetha62', 'Magnitude62', 'Tetha63', 'Magnitude63', 'Magnitude64', 'Tetha65', 'Magnitude65', 'Y66', 'Tetha66', 'Magnitude66', 'Y67', 'Tetha67', 'Magnitude67', 'Tetha68', 'Magnitude68', 'Magnitude69', 'Tetha70', 'Magnitude70', 'Tetha71', 'Magnitude71', 'Tetha72', 'Magnitude72', 'Tetha73', 'Magnitude73', 'X74', 'Y74', 'Tetha74', 'Magnitude74', 'X75', 'Y75', 'Tetha75', 'Magnitude75', 'X76', 'Y76', 'Tetha76', 'Magnitude76', 'X77', 'Y77', 'Tetha77', 'Magnitude77', 'X78', 'Y78', 'Tetha78', 'Magnitude78', 'X79', 'Y79', 'Tetha79', 'Magnitude79', 'X80', 'Y80', 'Tetha80', 'Magnitude80', 'X81', 'Tetha81', 'Magnitude81', 'X82', 'Tetha82', 'Magnitude82', 'X83', 'Tetha83', 'Magnitude83', 'X84', 'Tetha84', 'Magnitude84', 'Tetha85', 'Magnitude85', 'Tetha86', 'Magnitude86', 'X87', 'Y87', 'Tetha87', 'Magnitude87', 'Tetha88', 'Magnitude88', 'Tetha89', 'Magnitude89', 'Tetha90', 'Magnitude90', 'X91', 'Tetha91', 'Magnitude91', 'X92', 'Tetha92', 'Magnitude92', 'X93', 'Tetha93', 'Magnitude93', 'X94', 'Y94', 'Tetha94', 'Magnitude94', 'X95', 'Y95', 'Tetha95', 'Magnitude95', 'X96', 'Y96', 'Tetha96', 'Magnitude96', 'X97', 'Y97', 'Tetha97', 'Magnitude97', 'X98', 'Y98', 'Tetha98', 'Magnitude98', 'X99', 'Y99', 'Tetha99', 'Magnitude99', 'X100', 'Y100', 'Tetha100', 'Magnitude100']\n",
      "  Classification Accuracy with RFE: 98.55%\n",
      "  Original Features Accuracy: 98.57%\n",
      "  Accuracy Difference: -0.02%\n",
      "  Output saved to: output-baru/rfe_results\\rfe_mulut.csv\n",
      "\n",
      "Warning: nilai-fitur-all-component.csv contains 147840 NaN values. Imputing missing values.\n",
      "RFE Results for nilai-fitur-all-component.csv:\n",
      "  Original Features: 960\n",
      "  Selected Features: 280\n",
      "  Selected Feature Names: ['mulut-Tetha3', 'mulut-Magnitude3', 'mulut-Magnitude7', 'mulut-Tetha9', 'mulut-Magnitude9', 'mulut-Magnitude14', 'mulut-Magnitude15', 'mulut-Magnitude16', 'mulut-Tetha17', 'mulut-Magnitude17', 'mulut-Tetha18', 'mulut-Magnitude18', 'mulut-Tetha19', 'mulut-Magnitude19', 'mulut-Tetha20', 'mulut-Magnitude20', 'mulut-Tetha21', 'mulut-Magnitude21', 'mulut-Magnitude22', 'mulut-Tetha30', 'mulut-Magnitude30', 'mulut-Magnitude32', 'mulut-Tetha33', 'mulut-Magnitude33', 'mulut-Tetha34', 'mulut-Magnitude34', 'mulut-Tetha35', 'mulut-Magnitude35', 'mulut-Tetha36', 'mulut-Magnitude36', 'mulut-Magnitude37', 'mulut-Tetha38', 'mulut-Magnitude38', 'mulut-Tetha39', 'mulut-Magnitude39', 'mulut-Tetha40', 'mulut-Magnitude40', 'mulut-Tetha41', 'mulut-Magnitude41', 'mulut-Tetha43', 'mulut-Magnitude43', 'mulut-Tetha51', 'mulut-Magnitude51', 'mulut-Magnitude52', 'mulut-Tetha54', 'mulut-Magnitude54', 'mulut-Tetha55', 'mulut-Magnitude55', 'mulut-Tetha56', 'mulut-Magnitude56', 'mulut-Tetha57', 'mulut-Magnitude57', 'mulut-Tetha58', 'mulut-Magnitude58', 'mulut-Magnitude59', 'mulut-Tetha60', 'mulut-Magnitude60', 'mulut-Magnitude61', 'mulut-Magnitude62', 'mulut-Magnitude63', 'mulut-Magnitude64', 'mulut-Magnitude66', 'mulut-Magnitude70', 'mulut-Magnitude72', 'mulut-Tetha74', 'mulut-Magnitude74', 'mulut-Tetha75', 'mulut-Magnitude75', 'mulut-Magnitude76', 'mulut-Tetha77', 'mulut-Magnitude77', 'mulut-Tetha78', 'mulut-Magnitude78', 'mulut-Magnitude79', 'mulut-Magnitude80', 'mulut-X81', 'mulut-Tetha81', 'mulut-Magnitude81', 'mulut-Magnitude82', 'mulut-Magnitude83', 'mulut-Magnitude84', 'mulut-Magnitude85', 'mulut-Tetha86', 'mulut-Magnitude86', 'mulut-Magnitude89', 'mulut-Tetha91', 'mulut-Magnitude91', 'mulut-Magnitude92', 'mulut-Magnitude93', 'mulut-Tetha94', 'mulut-Magnitude94', 'mulut-Tetha95', 'mulut-Magnitude95', 'mulut-Tetha96', 'mulut-Magnitude96', 'mulut-Tetha97', 'mulut-Magnitude97', 'mulut-Tetha98', 'mulut-Magnitude98', 'mulut-Tetha99', 'mulut-Magnitude99', 'mulut-Tetha100', 'mulut-Magnitude100', 'alis-Magnitude1', 'alis-Tetha2', 'alis-Magnitude2', 'alis-Magnitude3', 'alis-Magnitude4', 'alis-Tetha5', 'alis-Magnitude5', 'alis-Tetha7', 'alis-Magnitude7', 'alis-Tetha8', 'alis-Magnitude8', 'alis-Tetha9', 'alis-Magnitude9', 'alis-Magnitude10', 'alis-Magnitude11', 'alis-Magnitude12', 'alis-Magnitude13', 'alis-Magnitude14', 'alis-Tetha15', 'alis-Magnitude15', 'alis-Tetha16', 'alis-Magnitude16', 'alis-Tetha17', 'alis-Magnitude17', 'alis-Magnitude18', 'alis-Tetha19', 'alis-Magnitude19', 'alis-Tetha20', 'alis-Magnitude20', 'alis-X21', 'alis-Tetha21', 'alis-Magnitude21', 'alis-Tetha22', 'alis-Magnitude22', 'alis-Tetha23', 'alis-Magnitude23', 'alis-Tetha24', 'alis-Magnitude24', 'alis-Tetha25', 'alis-Magnitude25', 'alis-Tetha26', 'alis-Magnitude26', 'alis-Tetha27', 'alis-Magnitude27', 'alis-Tetha28', 'alis-Magnitude28', 'alis-Tetha29', 'alis-Magnitude29', 'alis-Tetha30', 'alis-Magnitude30', 'alis-Magnitude31', 'alis-Magnitude35', 'alis-Magnitude36', 'alis-Tetha37', 'alis-Magnitude37', 'alis-Tetha38', 'alis-Magnitude38', 'alis-Magnitude39', 'alis-Tetha40', 'alis-Magnitude40', 'alis-Magnitude44', 'alis-Tetha46', 'alis-Magnitude46', 'alis-Tetha47', 'alis-Magnitude47', 'alis-Tetha48', 'alis-Magnitude48', 'alis-Tetha49', 'alis-Magnitude49', 'alis-Tetha50', 'alis-Magnitude50', 'alis-Tetha51', 'alis-Magnitude51', 'alis-Tetha52', 'alis-Magnitude52', 'alis-Magnitude53', 'alis-Magnitude54', 'alis-Tetha55', 'alis-Magnitude55', 'alis-Tetha56', 'alis-Magnitude56', 'alis-X57', 'alis-Tetha57', 'alis-Magnitude57', 'alis-Magnitude58', 'alis-Tetha59', 'alis-Magnitude59', 'alis-Tetha60', 'alis-Magnitude65', 'alis-Tetha66', 'alis-Magnitude66', 'alis-Magnitude67', 'alis-Magnitude68', 'alis-Magnitude70', 'alis-Magnitude74', 'alis-Tetha75', 'alis-Magnitude75', 'alis-Tetha76', 'alis-Magnitude76', 'alis-Tetha77', 'alis-Magnitude77', 'alis-Magnitude78', 'alis-Tetha79', 'alis-Magnitude79', 'alis-Tetha80', 'alis-Magnitude80', 'alis-Tetha81', 'alis-Magnitude81', 'alis-Tetha82', 'alis-Magnitude82', 'alis-Tetha83', 'alis-Magnitude83', 'alis-Tetha84', 'alis-Magnitude84', 'alis-X85', 'alis-Tetha85', 'alis-Magnitude85', 'alis-Tetha88', 'alis-Magnitude88', 'alis-Tetha93', 'alis-Magnitude93', 'alis-Magnitude94', 'alis-Magnitude95', 'alis-Tetha96', 'alis-Magnitude96', 'alis-Magnitude97', 'alis-Tetha100', 'alis-Magnitude100', 'alis-Magnitude101', 'alis-Tetha102', 'alis-Magnitude102', 'alis-Tetha103', 'alis-Magnitude103', 'alis-Tetha104', 'alis-Magnitude104', 'alis-Tetha105', 'alis-Magnitude105', 'alis-Tetha106', 'alis-Magnitude106', 'alis-Tetha107', 'alis-Magnitude107', 'alis-Tetha108', 'alis-Magnitude108', 'alis-Tetha109', 'alis-Magnitude109', 'alis-Magnitude110', 'alis-Tetha111', 'alis-Magnitude111', 'alis-Tetha112', 'alis-Magnitude112', 'alis-Tetha113', 'alis-Magnitude113', 'alis-Magnitude115', 'alis-Tetha125', 'alis-Magnitude125', 'alis-Magnitude127', 'alis-Magnitude128', 'alis-Tetha130', 'alis-Magnitude130', 'alis-X131', 'alis-Magnitude131', 'alis-Tetha132', 'alis-Magnitude132', 'alis-Tetha133', 'alis-Magnitude133', 'alis-Tetha134', 'alis-Magnitude134', 'alis-Tetha135', 'alis-Magnitude135', 'alis-Tetha136', 'alis-Magnitude136', 'alis-Magnitude137', 'alis-Magnitude138', 'alis-Tetha139', 'alis-Magnitude139', 'alis-Tetha140', 'alis-Magnitude140']\n",
      "  Classification Accuracy with RFE: 99.30%\n",
      "  Original Features Accuracy: 99.38%\n",
      "  Accuracy Difference: -0.07%\n",
      "  Output saved to: output-baru/rfe_results\\rfe_nilai-fitur-all-component.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def perform_rfe_feature_selection(input_dir, output_dir, n_features_to_select=None, step=1):\n",
    "    \"\"\"\n",
    "    Perform RFE (Recursive Feature Elimination) feature selection on CSV files in the input directory\n",
    "    and evaluate classification accuracy\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        Directory containing input CSV files\n",
    "    output_dir : str\n",
    "        Directory to save RFE results\n",
    "    n_features_to_select : int or None\n",
    "        Number of features to select. If None, half of the features will be selected.\n",
    "    step : int\n",
    "        Number of features to remove at each iteration\n",
    "    \"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files in the input directory\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # Full path to the CSV file\n",
    "            input_path = os.path.join(input_dir, csv_file)\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(input_path)\n",
    "            \n",
    "            # Check for NaN values and print summary\n",
    "            nan_count = df.isna().sum().sum()\n",
    "            if nan_count > 0:\n",
    "                print(f\"Warning: {csv_file} contains {nan_count} NaN values. Imputing missing values.\")\n",
    "                \n",
    "            # Remove non-numeric columns for RFE\n",
    "            numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "            X = df[numeric_columns]\n",
    "            \n",
    "            # Separate features from metadata columns\n",
    "            metadata_columns = []\n",
    "            for col in ['Frame', 'Folder Path']:\n",
    "                if col in df.columns:\n",
    "                    metadata_columns.append(col)\n",
    "                    \n",
    "            label_column = 'Label'\n",
    "            \n",
    "            # Check if label column exists in the DataFrame\n",
    "            if label_column not in df.columns:\n",
    "                print(f\"Warning: '{label_column}' column not found in {csv_file}. Skipping accuracy calculation.\")\n",
    "                continue\n",
    "                \n",
    "            metadata = df[metadata_columns] if metadata_columns else pd.DataFrame()\n",
    "            y = df[label_column]\n",
    "            \n",
    "            # Remove any metadata columns from features if they were included in numeric_columns\n",
    "            X = X.drop(columns=[col for col in metadata_columns if col in X.columns], errors='ignore')\n",
    "            \n",
    "            # Handle missing values with SimpleImputer\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_imputed = imputer.fit_transform(X)\n",
    "            \n",
    "            # Standardize the features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_imputed)\n",
    "            \n",
    "            # Create column names for scaled data\n",
    "            feature_names = X.columns.tolist()\n",
    "            \n",
    "            # Set default n_features_to_select if None\n",
    "            if n_features_to_select is None:\n",
    "                n_features_to_select = max(1, X.shape[1] // 2)  # Select half of the features by default\n",
    "                \n",
    "            # Create a base estimator (Random Forest classifier)\n",
    "            estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            \n",
    "            # Create RFE with the estimator\n",
    "            rfe = RFE(estimator=estimator, n_features_to_select=n_features_to_select, step=step)\n",
    "            \n",
    "            # Fit RFE\n",
    "            rfe.fit(X_scaled, y)\n",
    "            \n",
    "            # Get selected features\n",
    "            selected_features_mask = rfe.support_\n",
    "            selected_features = [feature for feature, selected in zip(feature_names, selected_features_mask) if selected]\n",
    "            \n",
    "            # Transform data using selected features\n",
    "            X_rfe = X_scaled[:, selected_features_mask]\n",
    "            \n",
    "            # Print feature ranking\n",
    "            feature_ranking = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Ranking': rfe.ranking_,\n",
    "                'Selected': selected_features_mask\n",
    "            }).sort_values('Ranking')\n",
    "            \n",
    "            # Save feature ranking\n",
    "            feature_ranking.to_csv(os.path.join(output_dir, f'feature_ranking_{csv_file}'), index=False)\n",
    "            \n",
    "            # Create a DataFrame with RFE results\n",
    "            df_rfe = pd.DataFrame(X_rfe, columns=[f'Feature_{i+1}' for i in range(X_rfe.shape[1])])\n",
    "            \n",
    "            # Add original selected feature names as metadata\n",
    "            feature_mapping = pd.DataFrame({\n",
    "                'RFE_Feature': [f'Feature_{i+1}' for i in range(len(selected_features))],\n",
    "                'Original_Feature': selected_features\n",
    "            })\n",
    "            feature_mapping.to_csv(os.path.join(output_dir, f'feature_mapping_{csv_file}'), index=False)\n",
    "            \n",
    "            # Add back the metadata columns and label\n",
    "            if not metadata.empty:\n",
    "                df_rfe = pd.concat([metadata, df_rfe], axis=1)\n",
    "            df_rfe[label_column] = y\n",
    "            \n",
    "            # Save RFE results\n",
    "            output_csv = os.path.join(output_dir, f'rfe_{csv_file}')\n",
    "            df_rfe.to_csv(output_csv, index=False)\n",
    "            \n",
    "            # Calculate accuracy using the classifier\n",
    "            # Split data into training and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_rfe, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "            )\n",
    "            \n",
    "            # Train the classifier\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Generate and save classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_csv(os.path.join(output_dir, f'classification_report_{csv_file}'))\n",
    "            \n",
    "            # Generate confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix - {csv_file}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'confusion_matrix_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Compare with original features accuracy\n",
    "            X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
    "                X_scaled, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "            )\n",
    "            clf_original = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf_original.fit(X_train_orig, y_train_orig)\n",
    "            y_pred_orig = clf_original.predict(X_test_orig)\n",
    "            accuracy_orig = accuracy_score(y_test_orig, y_pred_orig)\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"RFE Results for {csv_file}:\")\n",
    "            print(f\"  Original Features: {X.shape[1]}\")\n",
    "            print(f\"  Selected Features: {len(selected_features)}\")\n",
    "            print(f\"  Selected Feature Names: {selected_features}\")\n",
    "            print(f\"  Classification Accuracy with RFE: {accuracy * 100:.2f}%\")\n",
    "            print(f\"  Original Features Accuracy: {accuracy_orig * 100:.2f}%\")\n",
    "            print(f\"  Accuracy Difference: {(accuracy - accuracy_orig) * 100:.2f}%\")\n",
    "            print(f\"  Output saved to: {output_csv}\\n\")\n",
    "            \n",
    "            # Plot accuracy comparison\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.bar(['Original Features', 'RFE Selected Features'], [accuracy_orig, accuracy], color=['blue', 'green'])\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Accuracy Comparison - {csv_file}')\n",
    "            plt.ylim(0, 1.1)\n",
    "            for i, v in enumerate([accuracy_orig, accuracy]):\n",
    "                plt.text(i, v + 0.05, f'{v:.2%}', ha='center')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'accuracy_comparison_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Plot feature importance of selected features\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            plt.bar(range(len(importances)), importances[indices])\n",
    "            plt.xticks(range(len(importances)), [f'Feature_{i+1}' for i in indices], rotation=90)\n",
    "            plt.title(f'Feature Importance of Selected Features - {csv_file}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'feature_importance_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Directories for input and output\n",
    "input_dir = 'output-baru/csv'  # Update this to match your directory structure\n",
    "output_dir = 'output-baru/rfe_results'\n",
    "\n",
    "# Run RFE feature selection\n",
    "# You can adjust n_features_to_select to set the number of features you want to keep\n",
    "# If set to None, it will select half of the features by default\n",
    "perform_rfe_feature_selection(input_dir, output_dir, n_features_to_select=None, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses file raw data: alis.csv\n",
      "  Peringatan: Data mengandung 86240 nilai NaN. Melakukan imputasi...\n",
      "Hasil Akurasi Raw Data untuk alis.csv:\n",
      "  Jumlah Fitur: 560\n",
      "  Akurasi: 99.08%\n",
      "  Report disimpan di: output-baru/accuracy_analysis\\raw_accuracy_report_alis.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fina Orivia\\AppData\\Local\\Temp\\ipykernel_26796\\3163266839.py:106: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_df = pd.concat([summary_df, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses file raw data: mulut.csv\n",
      "  Peringatan: Data mengandung 61600 nilai NaN. Melakukan imputasi...\n",
      "Hasil Akurasi Raw Data untuk mulut.csv:\n",
      "  Jumlah Fitur: 400\n",
      "  Akurasi: 98.57%\n",
      "  Report disimpan di: output-baru/accuracy_analysis\\raw_accuracy_report_mulut.csv\n",
      "\n",
      "Memproses file raw data: nilai-fitur-all-component.csv\n",
      "  Peringatan: Data mengandung 147840 nilai NaN. Melakukan imputasi...\n",
      "Hasil Akurasi Raw Data untuk nilai-fitur-all-component.csv:\n",
      "  Jumlah Fitur: 960\n",
      "  Akurasi: 99.38%\n",
      "  Report disimpan di: output-baru/accuracy_analysis\\raw_accuracy_report_nilai-fitur-all-component.csv\n",
      "\n",
      "Ringkasan akurasi raw data disimpan di: output-baru/accuracy_analysis\\raw_summary_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_raw_data_accuracy(input_dir, results_dir):\n",
    "    \"\"\"\n",
    "    Menghitung akurasi dari raw data CSV\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        Direktori yang berisi file raw data CSV\n",
    "    results_dir : str\n",
    "        Direktori untuk menyimpan hasil analisis akurasi\n",
    "    \"\"\"\n",
    "    # Buat direktori hasil jika belum ada\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Cari semua file CSV di direktori input\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # Buat file ringkasan untuk semua hasil\n",
    "    summary_df = pd.DataFrame(columns=['File', 'Jumlah_Fitur', 'Akurasi'])\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            print(f\"Memproses file raw data: {csv_file}\")\n",
    "            \n",
    "            # Jalur penuh ke file CSV\n",
    "            input_path = os.path.join(input_dir, csv_file)\n",
    "            \n",
    "            # Baca file CSV\n",
    "            df = pd.read_csv(input_path)\n",
    "            \n",
    "            # Cari kolom label\n",
    "            label_column = 'Label'\n",
    "            if label_column not in df.columns:\n",
    "                print(f\"Peringatan: Kolom '{label_column}' tidak ditemukan di {csv_file}. Mencoba menemukan kolom label lain...\")\n",
    "                # Coba cari kolom label lain\n",
    "                possible_labels = [col for col in df.columns if 'label' in col.lower() or 'kelas' in col.lower() or 'class' in col.lower()]\n",
    "                if possible_labels:\n",
    "                    label_column = possible_labels[0]\n",
    "                    print(f\"Menggunakan kolom '{label_column}' sebagai label.\")\n",
    "                else:\n",
    "                    print(f\"Tidak dapat menemukan kolom label di {csv_file}. Melewati file ini.\")\n",
    "                    continue\n",
    "            \n",
    "            # Pisahkan fitur dan label\n",
    "            y = df[label_column]\n",
    "            \n",
    "            # Pisahkan kolom metadata dan non-numerik\n",
    "            metadata_columns = []\n",
    "            for col in ['Frame', 'Folder Path', label_column]:\n",
    "                if col in df.columns:\n",
    "                    metadata_columns.append(col)\n",
    "                    \n",
    "            # Hanya gunakan kolom numerik untuk model\n",
    "            numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "            X = df[numeric_columns]\n",
    "            \n",
    "            # Hapus kolom metadata dari X jika ada\n",
    "            X = X.drop(columns=[col for col in metadata_columns if col in X.columns], errors='ignore')\n",
    "            \n",
    "            # Cek dan tangani nilai NaN\n",
    "            nan_count = X.isna().sum().sum()\n",
    "            if nan_count > 0:\n",
    "                print(f\"  Peringatan: Data mengandung {nan_count} nilai NaN. Melakukan imputasi...\")\n",
    "                imputer = SimpleImputer(strategy='mean')\n",
    "                X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "            \n",
    "            # Standardisasi fitur\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "            \n",
    "            # Bagi data menjadi training dan testing\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, y, test_size=0.3, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    "            )\n",
    "            \n",
    "            # Latih model Random Forest\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Prediksi dan hitung akurasi\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Buat dan simpan classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_csv(os.path.join(results_dir, f'raw_accuracy_report_{csv_file}'))\n",
    "            \n",
    "            # Tampilkan ringkasan\n",
    "            print(f\"Hasil Akurasi Raw Data untuk {csv_file}:\")\n",
    "            print(f\"  Jumlah Fitur: {X.shape[1]}\")\n",
    "            print(f\"  Akurasi: {accuracy * 100:.2f}%\")\n",
    "            print(f\"  Report disimpan di: {os.path.join(results_dir, f'raw_accuracy_report_{csv_file}')}\\n\")\n",
    "            \n",
    "            # Tambahkan ke dataframe ringkasan\n",
    "            summary_df = pd.concat([summary_df, pd.DataFrame({\n",
    "                'File': [csv_file],\n",
    "                'Jumlah_Fitur': [X.shape[1]],\n",
    "                'Akurasi': [accuracy * 100]\n",
    "            })], ignore_index=True)\n",
    "            \n",
    "            # Visualisasi fitur importance (top 20 jika terlalu banyak fitur)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            \n",
    "            # Tunjukkan maksimal 20 fitur paling penting\n",
    "            top_n = min(20, len(importances))\n",
    "            plt.bar(range(top_n), importances[indices[:top_n]])\n",
    "            plt.xticks(range(top_n), X.columns[indices[:top_n]], rotation=90)\n",
    "            plt.title(f'20 Fitur Terpenting - {csv_file}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(results_dir, f'raw_feature_importance_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saat memproses raw data {csv_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Simpan ringkasan akurasi untuk semua file\n",
    "    if not summary_df.empty:\n",
    "        summary_df = summary_df.sort_values('Akurasi', ascending=False)\n",
    "        summary_df.to_csv(os.path.join(results_dir, 'raw_summary_accuracy.csv'), index=False)\n",
    "        print(f\"Ringkasan akurasi raw data disimpan di: {os.path.join(results_dir, 'raw_summary_accuracy.csv')}\")\n",
    "        \n",
    "        # Visualisasi perbandingan akurasi\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.bar(summary_df['File'], summary_df['Akurasi'], color='lightgreen')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('Akurasi (%)')\n",
    "        plt.title('Perbandingan Akurasi Raw Data')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'raw_accuracy_comparison.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Direktori yang berisi raw data CSV dan direktori untuk menyimpan hasil analisis\n",
    "input_dir = 'output-baru/csv'  # Sesuaikan dengan direktori raw data Anda\n",
    "results_dir = 'output-baru/accuracy_analysis'\n",
    "\n",
    "# Hitung akurasi dari raw data\n",
    "calculate_raw_data_accuracy(input_dir, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Results for rfe_alis.csv:\n",
      "Cross-Validation Scores: [0.99141564 0.98813797 0.98954106 0.98954106 0.99016547]\n",
      "Mean CV Score: 0.9898 (+/- 0.0021)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Rendah       0.99      0.99      0.99      3536\n",
      "Sangat Rendah       1.00      0.98      0.99       936\n",
      "Sangat Tinggi       1.00      0.98      0.99       832\n",
      "       Tinggi       0.98      1.00      0.99      2704\n",
      "\n",
      "     accuracy                           0.99      8008\n",
      "    macro avg       0.99      0.99      0.99      8008\n",
      " weighted avg       0.99      0.99      0.99      8008\n",
      "\n",
      "\n",
      "Classification Results for rfe_mulut.csv:\n",
      "Cross-Validation Scores: [0.98532855 0.98002185 0.98157977 0.97830159 0.97970653]\n",
      "Mean CV Score: 0.9810 (+/- 0.0048)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Rendah       0.97      0.99      0.98      3536\n",
      "Sangat Rendah       0.99      0.96      0.98       936\n",
      "Sangat Tinggi       0.99      0.95      0.97       832\n",
      "       Tinggi       0.99      0.98      0.98      2704\n",
      "\n",
      "     accuracy                           0.98      8008\n",
      "    macro avg       0.99      0.97      0.98      8008\n",
      " weighted avg       0.98      0.98      0.98      8008\n",
      "\n",
      "\n",
      "Classification Results for rfe_nilai-fitur-all-component.csv:\n",
      "Cross-Validation Scores: [0.99531762 0.99422507 0.99391196 0.99297534 0.99500468]\n",
      "Mean CV Score: 0.9943 (+/- 0.0017)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Rendah       0.99      1.00      1.00      3536\n",
      "Sangat Rendah       1.00      0.99      0.99       936\n",
      "Sangat Tinggi       1.00      0.98      0.99       832\n",
      "       Tinggi       0.99      1.00      0.99      2704\n",
      "\n",
      "     accuracy                           0.99      8008\n",
      "    macro avg       1.00      0.99      0.99      8008\n",
      " weighted avg       0.99      0.99      0.99      8008\n",
      "\n",
      "\n",
      "Classification summary saved to classification_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def perform_svm_classification(input_dir, results_dir):\n",
    "    \"\"\"\n",
    "    Perform SVM Classification on feature-selected datasets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        Directory containing feature-selected CSV files\n",
    "    results_dir : str\n",
    "        Directory to save classification results\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files in the input directory\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.startswith('rfe_') and f.endswith('.csv')]\n",
    "    \n",
    "    # Summary of results\n",
    "    classification_summary = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # Full path to the CSV file\n",
    "        input_path = os.path.join(input_dir, csv_file)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(input_path)\n",
    "        \n",
    "        # Separate features and target\n",
    "        metadata_columns = ['Frame', 'Folder Path', 'Label']\n",
    "        X = df.drop(columns=metadata_columns)\n",
    "        y = df['Label']\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=0.2,  # 80% training, 20% testing\n",
    "            random_state=42,  # for reproducibility\n",
    "            stratify=y  # ensure proportional class distribution\n",
    "        )\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Initialize and train SVM\n",
    "        svm = SVC(\n",
    "            kernel='rbf',  # Radial Basis Function kernel\n",
    "            C=1.0,  # Regularization parameter\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(svm, X_train_scaled, y_train, cv=5)\n",
    "        \n",
    "        # Fit the model\n",
    "        svm.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = svm.predict(X_test_scaled)\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Visualize Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {csv_file}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'confusion_matrix_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Store summary\n",
    "        summary_entry = {\n",
    "            'Dataset': csv_file,\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'Macro Avg F1-Score': report['macro avg']['f1-score'],\n",
    "            'Cross-Val Mean': cv_scores.mean(),\n",
    "            'Cross-Val Std': cv_scores.std()\n",
    "        }\n",
    "        classification_summary.append(summary_entry)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nClassification Results for {csv_file}:\")\n",
    "        print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary_df = pd.DataFrame(classification_summary)\n",
    "    summary_df.to_csv(os.path.join(results_dir, 'classification_summary.csv'), index=False)\n",
    "    print(\"\\nClassification summary saved to classification_summary.csv\")\n",
    "\n",
    "# Directories for input and output\n",
    "input_dir = 'output-baru/rfe_results'\n",
    "results_dir = 'output-baru/svm_classification_results'\n",
    "\n",
    "# Run SVM Classification\n",
    "perform_svm_classification(input_dir, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification summary saved to classification_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def perform_svm_classification(input_dir, results_dir):\n",
    "    \"\"\"\n",
    "    Perform SVM Classification on feature-selected datasets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        Directory containing feature-selected CSV files\n",
    "    results_dir : str\n",
    "        Directory to save classification results\n",
    "    \"\"\"\n",
    "    # Create results directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files in the input directory\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.startswith('rfe_') and f.endswith('.csv')]\n",
    "    \n",
    "    # Summary of results\n",
    "    classification_summary = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # Full path to the CSV file\n",
    "        input_path = os.path.join(input_dir, csv_file)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(input_path)\n",
    "        \n",
    "        # Separate features and target\n",
    "        metadata_columns = ['Frame', 'Folder Path', 'Label']\n",
    "        X = df.drop(columns=metadata_columns)\n",
    "        y = df['Label']\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=0.2,  # 80% training, 20% testing\n",
    "            random_state=42,  # for reproducibility\n",
    "            stratify=y  # ensure proportional class distribution\n",
    "        )\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Initialize and train SVM\n",
    "        svm = SVC(\n",
    "            kernel='rbf',  # Radial Basis Function kernel\n",
    "            C=1.0,  # Regularization parameter\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(svm, X_train_scaled, y_train, cv=5)\n",
    "        \n",
    "        # Fit the model\n",
    "        svm.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = svm.predict(X_test_scaled)\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Visualize Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {csv_file}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'confusion_matrix_{csv_file.replace(\".csv\", \".png\")}'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Store summary\n",
    "        summary_entry = {\n",
    "            'Dataset': csv_file,\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'Macro Avg F1-Score': report['macro avg']['f1-score'],\n",
    "            'Cross-Val Mean': cv_scores.mean(),\n",
    "            'Cross-Val Std': cv_scores.std()\n",
    "        }\n",
    "        classification_summary.append(summary_entry)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nClassification Results for {csv_file}:\")\n",
    "        print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary_df = pd.DataFrame(classification_summary)\n",
    "    summary_df.to_csv(os.path.join(results_dir, 'classification_summary.csv'), index=False)\n",
    "    print(\"\\nClassification summary saved to classification_summary.csv\")\n",
    "\n",
    "# Directories for input and output\n",
    "input_dir = 'output-baru/pca_results'\n",
    "results_dir = 'output-baru/svm_classification_results'\n",
    "\n",
    "# Run SVM Classification\n",
    "perform_svm_classification(input_dir, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values before imputation: 147840\n",
      "NaN values after imputation: 0\n",
      "output-baru/csv/cleaned-nilai-fitur-all-component.csv\n",
      "\n",
      "Best combination found:\n",
      "{'C': 1, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "Best accuracy: 0.9931318681318682\n",
      "Accuracy: 0.9931318681318682\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3539    0    1   10]\n",
      " [   6  950    0    4]\n",
      " [  10    0  794    5]\n",
      " [  19    0    0 2670]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from clasification.svm import SVMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset and initialize the classifier\n",
    "dataset_file = 'output-baru/csv/nilai-fitur-all-component.csv'\n",
    "label_column = 'Label'\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']  # Columns to exclude\n",
    "\n",
    "# Load the data first to handle NaN values\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Check for NaN values\n",
    "print(f\"NaN values before imputation: {data.isna().sum().sum()}\")\n",
    "\n",
    "# Option 1: Drop rows with NaN values\n",
    "# data = data.dropna()\n",
    "\n",
    "# Option 2: Impute NaN values with mean (recommended)\n",
    "features = [col for col in data.columns if col not in except_feature_columns]\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[features] = imputer.fit_transform(data[features])\n",
    "\n",
    "# Verify NaN values are gone\n",
    "print(f\"NaN values after imputation: {data.isna().sum().sum()}\")\n",
    "\n",
    "# Save the cleaned data or use it directly\n",
    "cleaned_dataset_file = 'output-baru/csv/cleaned-nilai-fitur-all-component.csv'\n",
    "data.to_csv(cleaned_dataset_file, index=False)\n",
    "\n",
    "# Initialize the classifier with cleaned data\n",
    "classifier = SVMClassifier(cleaned_dataset_file, label_column, except_feature_column=except_feature_columns)\n",
    "\n",
    "# Load, split, train, evaluate and save the model\n",
    "classifier.load_data()\n",
    "classifier.split_data(test_size=0.2)\n",
    "classifier.train_model(autoParams=True)\n",
    "classifier.evaluate_model()\n",
    "classifier.save_model('svm_model_random_sampling.joblib', 'label_encoder_random_sampling.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def perform_svm_classification(input_dir, results_dir):\n",
    "    \"\"\"\n",
    "    Perform SVM Classification menggunakan berbagai metode seleksi fitur\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_dir : str\n",
    "        Direktori berisi file CSV\n",
    "    results_dir : str\n",
    "        Direktori untuk menyimpan hasil klasifikasi\n",
    "    \"\"\"\n",
    "    # Buat direktori hasil\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Daftar file CSV\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # Ringkasan hasil klasifikasi\n",
    "    classification_summary = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # Path lengkap file CSV\n",
    "        input_path = os.path.join(input_dir, csv_file)\n",
    "        \n",
    "        # Baca file CSV\n",
    "        df = pd.read_csv(input_path)\n",
    "        \n",
    "        # Pisahkan fitur dan target\n",
    "        metadata_columns = ['Frame', 'Folder Path', 'Label']\n",
    "        X = df.drop(columns=metadata_columns)\n",
    "        y = df['Label']\n",
    "        \n",
    "        # Metode seleksi fitur yang akan diuji\n",
    "        feature_selection_methods = [\n",
    "            ('Raw Data', X),\n",
    "            ('RFE', perform_rfe_selection(X, y)),\n",
    "            ('PCA', perform_pca_selection(X))\n",
    "        ]\n",
    "        \n",
    "        for method_name, X_selected in feature_selection_methods:\n",
    "            # Bagi data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_selected, y, \n",
    "                test_size=0.2,  \n",
    "                random_state=42,  \n",
    "                stratify=y  \n",
    "            )\n",
    "            \n",
    "            # Skala fitur\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Inisiasi dan latih SVM\n",
    "            svm = SVC(\n",
    "                kernel='rbf',  \n",
    "                C=1.0,  \n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Validasi silang\n",
    "            cv_scores = cross_val_score(svm, X_train_scaled, y_train, cv=5)\n",
    "            \n",
    "            # Latih model\n",
    "            svm.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Prediksi\n",
    "            y_pred = svm.predict(X_test_scaled)\n",
    "            \n",
    "            # Buat laporan klasifikasi\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            \n",
    "            # Matriks konfusi\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Visualisasi matriks konfusi\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Matriks Konfusi - {csv_file} ({method_name})')\n",
    "            plt.ylabel('Label Sebenarnya')\n",
    "            plt.xlabel('Label Prediksi')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(results_dir, f'confusion_matrix_{csv_file.replace(\".csv\", \"\")}_{method_name}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Simpan ringkasan\n",
    "            summary_entry = {\n",
    "                'Dataset': csv_file,\n",
    "                'Metode Seleksi Fitur': method_name,\n",
    "                'Akurasi': report['accuracy'],\n",
    "                'Rata-rata F1 Makro': report['macro avg']['f1-score'],\n",
    "                'Rata-rata Skor CV': cv_scores.mean(),\n",
    "                'Std Skor CV': cv_scores.std()\n",
    "            }\n",
    "            classification_summary.append(summary_entry)\n",
    "            \n",
    "            # Cetak hasil\n",
    "            print(f\"\\nHasil Klasifikasi untuk {csv_file} ({method_name}):\")\n",
    "            print(f\"Skor Validasi Silang: {cv_scores}\")\n",
    "            print(f\"Rata-rata Skor CV: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "            print(\"\\nLaporan Klasifikasi:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Simpan ringkasan ke CSV\n",
    "    summary_df = pd.DataFrame(classification_summary)\n",
    "    summary_df.to_csv(os.path.join(results_dir, 'classification_summary.csv'), index=False)\n",
    "    print(\"\\nRingkasan klasifikasi disimpan di classification_summary.csv\")\n",
    "\n",
    "def perform_rfe_selection(X, y, n_features_to_select=10):\n",
    "    \"\"\"\n",
    "    Lakukan Recursive Feature Elimination (RFE)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Data fitur\n",
    "    y : Series\n",
    "        Label target\n",
    "    n_features_to_select : int, optional\n",
    "        Jumlah fitur yang akan dipilih\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame dengan fitur terpilih\n",
    "    \"\"\"\n",
    "    estimator = SVC(kernel=\"linear\")\n",
    "    selector = RFE(estimator, n_features_to_select=n_features_to_select)\n",
    "    selector = selector.fit(X, y)\n",
    "    return X.loc[:, selector.support_]\n",
    "\n",
    "def perform_pca_selection(X, n_components=10):\n",
    "    \"\"\"\n",
    "    Lakukan Principal Component Analysis (PCA)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Data fitur\n",
    "    n_components : int, optional\n",
    "        Jumlah komponen utama yang akan dipilih\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame dengan komponen utama\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return pd.DataFrame(X_pca)\n",
    "\n",
    "# Direktori input dan output\n",
    "input_dir = 'output-baru/rfe_results'\n",
    "results_dir = 'output-baru/svm_classification_results'\n",
    "\n",
    "# Jalankan Klasifikasi SVM\n",
    "perform_svm_classification(input_dir, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def extract_numeric_features(df):\n",
    "    \"\"\"\n",
    "    Extract only numeric columns for classification\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame with only numeric columns\n",
    "    \"\"\"\n",
    "    # Identify numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove 'Frame' column if it exists in numeric columns\n",
    "    if 'Frame' in numeric_columns:\n",
    "        numeric_columns.remove('Frame')\n",
    "    \n",
    "    return df[numeric_columns]\n",
    "\n",
    "def load_and_preprocess_data(csv_path):\n",
    "    \"\"\"\n",
    "    Load data from CSV and preprocess for SVM classification\n",
    "    \n",
    "    Parameters:\n",
    "    csv_path (str): Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X, y) where X is feature matrix and y is target labels\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Ensure label exists\n",
    "    if 'Label' not in df.columns:\n",
    "        raise ValueError(\"No 'Label' column found in the dataset\")\n",
    "    \n",
    "    # Extract only numeric features\n",
    "    X = extract_numeric_features(df)\n",
    "    \n",
    "    # Extract labels\n",
    "    y = df['Label']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, output_path):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix using matplotlib\n",
    "    \n",
    "    Parameters:\n",
    "    cm (array): Confusion matrix\n",
    "    classes (list): List of class labels\n",
    "    title (str): Title of the plot\n",
    "    output_path (str): Path to save the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def perform_svm_classification(X, y, component_name):\n",
    "    \"\"\"\n",
    "    Perform SVM classification with grid search and cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    X (DataFrame): Feature matrix\n",
    "    y (Series): Target labels\n",
    "    component_name (str): Name of the facial component being classified\n",
    "    \n",
    "    Returns:\n",
    "    dict: Classification results\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear', 'poly']\n",
    "    }\n",
    "    \n",
    "    # Create SVM classifier\n",
    "    svm = SVC(probability=True)\n",
    "    \n",
    "    # Perform Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=svm, \n",
    "        param_grid=param_grid, \n",
    "        cv=5, \n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit Grid Search\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Best model\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_svm.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(best_svm, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    # Visualization of Confusion Matrix\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, \n",
    "        classes=np.unique(y), \n",
    "        title=f'Confusion Matrix - {component_name}', \n",
    "        output_path=f'output-baru/confusion_matrix_{component_name}.png'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy,\n",
    "        'cross_val_scores': cv_scores,\n",
    "        'mean_cv_score': cv_scores.mean(),\n",
    "        'std_cv_score': cv_scores.std(),\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform SVM classification on different facial components\n",
    "    \"\"\"\n",
    "    # Path to CSV directory\n",
    "    csv_dir = 'output-baru/csv'\n",
    "    \n",
    "    # Results dictionary\n",
    "    classification_results = {}\n",
    "    \n",
    "    # Iterate through CSV files\n",
    "    for filename in os.listdir(csv_dir):\n",
    "        if filename.endswith('.csv') and not filename.startswith('nilai-fitur'):\n",
    "            # Full path to CSV\n",
    "            csv_path = os.path.join(csv_dir, filename)\n",
    "            \n",
    "            # Component name (without .csv)\n",
    "            component_name = os.path.splitext(filename)[0]\n",
    "            \n",
    "            print(f\"\\nProcessing classification for {component_name}\")\n",
    "            \n",
    "            # Load and preprocess data\n",
    "            try:\n",
    "                X, y = load_and_preprocess_data(csv_path)\n",
    "                \n",
    "                # Print dataset info for debugging\n",
    "                print(f\"Features shape: {X.shape}\")\n",
    "                print(f\"Labels shape: {y.shape}\")\n",
    "                print(f\"Unique labels: {y.unique()}\")\n",
    "                \n",
    "                # Perform classification\n",
    "                results = perform_svm_classification(X, y, component_name)\n",
    "                \n",
    "                # Store results\n",
    "                classification_results[component_name] = results\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"\\nResults for {component_name}:\")\n",
    "                print(\"Best Parameters:\", results['best_params'])\n",
    "                print(\"Accuracy:\", results['accuracy'])\n",
    "                print(\"Cross-Validation Scores:\", results['cross_val_scores'])\n",
    "                print(\"Mean CV Score:\", results['mean_cv_score'])\n",
    "                print(\"Classification Report:\\n\", results['classification_report'])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {component_name}: {e}\")\n",
    "                # Optional: Print full traceback for debugging\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    # Save detailed results to a text file\n",
    "    with open('output-baru/classification_results.txt', 'w') as f:\n",
    "        for component, results in classification_results.items():\n",
    "            f.write(f\"\\n--- {component} Classification Results ---\\n\")\n",
    "            f.write(f\"Best Parameters: {results['best_params']}\\n\")\n",
    "            f.write(f\"Accuracy: {results['accuracy']}\\n\")\n",
    "            f.write(f\"Cross-Validation Scores: {results['cross_val_scores']}\\n\")\n",
    "            f.write(f\"Mean CV Score: {results['mean_cv_score']}\\n\")\n",
    "            f.write(f\"Standard Deviation of CV Scores: {results['std_cv_score']}\\n\")\n",
    "            f.write(f\"Classification Report:\\n{results['classification_report']}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFOLD Fitur All Component\n",
    "from clasification.svm import SVMClassifier\n",
    "\n",
    "# Path dataset\n",
    "dataset_file = 'output-baru/csv/nilai-fitur-all-component.csv'\n",
    "label_column = 'Label'\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']  # Kolom yang dikecualikan\n",
    "\n",
    "# Inisialisasi classifier\n",
    "classifier_kfold = SVMClassifier(dataset_file, label_column, except_feature_column=except_feature_columns)\n",
    "\n",
    "# Load data\n",
    "classifier_kfold.load_data()\n",
    "\n",
    "# Train model menggunakan k-fold cross validation\n",
    "classifier_kfold.train_model_cross_validation(cv=10)\n",
    "\n",
    "# Evaluate model menggunakan k-fold cross validation\n",
    "classifier_kfold.evaluate_model_cross_validation()\n",
    "\n",
    "# Save model\n",
    "classifier_kfold.save_model('svm_model_kfold.joblib', 'label_encoder_kfold.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Sampling 4QMV\n",
    "from clasification.svm import SVMClassifier\n",
    "\n",
    "# Load the dataset and initialize the classifier\n",
    "# dataset_file = 'test-output/4qmv-all-component.csv'\n",
    "# dataset_file = 'test-output/nilai-fitur-all-component.csv'\n",
    "# dataset_file = 'output/csv/4qmv-all-component.csv'\n",
    "dataset_file = 'output-baru/csv/all-component.csv'\n",
    "label_column = 'Label'\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']  # Columns to exclude\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = SVMClassifier(dataset_file, label_column, except_feature_column=except_feature_columns)\n",
    "\n",
    "# Load, split, train, evaluate and save the model\n",
    "classifier.load_data()\n",
    "classifier.split_data(test_size=0.2)\n",
    "classifier.train_model(autoParams=True)\n",
    "classifier.evaluate_model()\n",
    "classifier.save_model('4qmv_svm_model_random_sampling.joblib', '4qmv_label_encoder_random_sampling.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Sampling 4QMV\n",
    "from clasification.svm import SVMClassifier\n",
    "\n",
    "# Load the dataset and initialize the classifier\n",
    "# dataset_file = 'test-output/4qmv-all-component.csv'\n",
    "# dataset_file = 'test-output/nilai-fitur-all-component.csv'\n",
    "# dataset_file = 'output/csv/4qmv-all-component.csv'\n",
    "# dataset_file = 'test-output/onsetoffset_tanpa_fear/4qmv-all-component.csv'\n",
    "dataset_file = 'output-baru/csv/4qmv-all-component.csv'\n",
    "label_column = 'Label'\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']  # Columns to exclude\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = SVMClassifier(dataset_file, label_column, except_feature_column=except_feature_columns)\n",
    "\n",
    "# Load, split, train, evaluate and save the model\n",
    "classifier.load_data()\n",
    "classifier.split_data(test_size=0.2)\n",
    "classifier.train_model(autoParams=True)\n",
    "classifier.evaluate_model()\n",
    "classifier.save_model('4qmv_svm_model_kfold.joblib', '4qmv_label_encoder_kfold.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFOLD 4QMV\n",
    "from clasification.svm import SVMClassifier\n",
    "\n",
    "# Load the dataset and initialize the classifier \n",
    "# dataset_file = 'test-output/4qmv-all-component.csv'\n",
    "# dataset_file = 'test-output/nilai-fitur-all-component.csv'\n",
    "# dataset_file = 'test-output/onsetoffset_tanpa_fear/4qmv-all-component.csv'\n",
    "dataset_file = 'output-baru/csv/4qmv-all-component.csv'\n",
    "label_column = 'Label'\n",
    "except_feature_columns = ['Frame', 'Folder Path', 'Label']  # Columns to exclude\n",
    "\n",
    "# Inisialisasi classifier\n",
    "classifier_kfold = SVMClassifier(dataset_file, label_column, except_feature_column=except_feature_columns)\n",
    "\n",
    "# Load data\n",
    "classifier_kfold.load_data()\n",
    "\n",
    "# Train model menggunakan k-fold cross validation\n",
    "classifier_kfold.train_model_cross_validation(cv=10)\n",
    "\n",
    "# Evaluate model menggunakan k-fold cross validation\n",
    "classifier_kfold.evaluate_model_cross_validation()\n",
    "\n",
    "# Save model\n",
    "classifier_kfold.save_model('4qmv_svm_model_kfold2.joblib', '4qmv_label_encoder_kfold2.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
